# Streaming

Streaming is key to building responsive agent apps. There are a few types of data you’ll want to stream:

1. [Agent progress](#streaming-agent-progress) (e.g., get updates after each agent graph node is executed).
2. [LLM tokens](#streaming-llm-tokens) as they’re generated by the agent LLM.
3. [Custom updates](#streaming-updates-from-tools) from tools (e.g., "Fetched 10/100 records").

## Streaming agent progress

To stream agent progress, you can call `agent.stream()` (or `.astream()`) method with [`stream_mode="updates"`](../../how-tos/streaming#updates). This will emit a new event after every agent step. For example, in a tool-calling loop with a single tool call you should see the following updates:

```
- update from LLM-calling node, returning an AI message with tool calls
- update from tool node, returning a tool message with tool execution results
- update from LLM-calling node, returning an AI message with a final response
```

=== "Sync"

    ```python
    agent = create_react_agent(
        model="anthropic:claude-3-7-sonnet-latest",
        tools=[get_weather],
    )
    # highlight-next-line
    for chunk in agent.stream(
        {"messages": "what is the weather in sf"},
        # highlight-next-line
        stream_mode="updates"
    ):
        print(chunk)
    ```

=== "Async"

    ```python
    agent = create_react_agent(
        model="anthropic:claude-3-7-sonnet-latest",
        tools=[get_weather],
    )
    # highlight-next-line
    async for chunk in agent.astream(
        {"messages": "what is the weather in sf"},
        # highlight-next-line
        stream_mode="updates"
    ):
        print(chunk)
    ```

See all streaming modes supported by LangGraph [here](../how-tos/index.md#streaming).

## Streaming LLM tokens

To stream LLM tokens, switch the streaming mode to `stream_mode="messages"`:

=== "Sync"

    ```python
    agent = create_react_agent(
        model="anthropic:claude-3-7-sonnet-latest",
        tools=[get_weather],
    )
    # highlight-next-line
    for token, metadata in agent.stream(
        {"messages": "what is the weather in sf"},
        # highlight-next-line
        stream_mode="messages"
    ):
        print("Token", token)
        print("Metadata", metadata)
    ```

=== "Async"

    ```python
    agent = create_react_agent(
        model="anthropic:claude-3-7-sonnet-latest",
        tools=[get_weather],
    )
    # highlight-next-line
    async for token, metadata in agent.astream(
        {"messages": "what is the weather in sf"},
        # highlight-next-line
        stream_mode="messages"
    ):
        print("Token", token)
        print("Metadata", metadata)
    ```

## Streaming updates from tools

To stream updates from inside the tools as they are executed, you can use LangGraph's `get_stream_writer` util.

!!! Note

    If you add `get_stream_writer` inside your tool, you won't be able to invoke the tool outside of a LangGraph execution context. 

=== "Sync"

    ```python
    # highlight-next-line
    from langgraph.config import get_stream_writer

    def get_weather(city: str) -> str:
        """Get weather for a given city."""
        # highlight-next-line
        writer = get_stream_writer()
        # stream any arbitrary data
        # highlight-next-line
        writer(f"Looking up data for city: {city}")
        return f"It's always sunny in {city}!"

    agent = create_react_agent(
        model="anthropic:claude-3-7-sonnet-latest",
        tools=[get_weather],
    )

    for chunk in agent.stream(
        {"messages": "what is the weather in sf"},
        # highlight-next-line
        stream_mode="custom"
    ):
        print(chunk)
    ```

=== "Async"

    ```python
    # highlight-next-line
    from langgraph.config import get_stream_writer

    def get_weather(city: str) -> str:
        # highlight-next-line
        writer = get_stream_writer()
        # stream any arbitrary data
        # highlight-next-line
        writer(f"Looking up data for city: {city}")
        return f"It's always sunny in {city}!"

    agent = create_react_agent(
        model="anthropic:claude-3-7-sonnet-latest",
        tools=[get_weather],
    )

    async for chunk in agent.astream(
        {"messages": "what is the weather in sf"},
        # highlight-next-line
        stream_mode="custom"
    ):
        print(chunk)
    ```