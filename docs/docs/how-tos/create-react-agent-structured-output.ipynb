{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "992c4695-ec4f-428d-bd05-fb3b5fbd70f4",
   "metadata": {},
   "source": [
    "# How to return structured output from the prebuilt ReAct agent\n",
    "\n",
    "!!! info \"Prerequisites\"\n",
    "    This guide assumes familiarity with the following:\n",
    "    \n",
    "    - [Agent Architectures](../../concepts/agentic_concepts/)\n",
    "    - [Chat Models](https://python.langchain.com/docs/concepts/chat_models/)\n",
    "    - [Tools](https://python.langchain.com/docs/concepts/tools/)\n",
    "    - [Structured Output](https://python.langchain.com/docs/concepts/structured_outputs/)\n",
    "\n",
    "To return structured output from the prebuilt ReAct agent you can provide a `response_format` parameter with the desired output schema to [create_react_agent][langgraph.prebuilt.chat_agent_executor.create_react_agent]:\n",
    "\n",
    "```python\n",
    "class ResponseFormat(BaseModel):\n",
    "    \"\"\"Respond to the user in this format.\"\"\"\n",
    "    my_special_output: str\n",
    "\n",
    "\n",
    "graph = create_react_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    # specify the schema for the structured output using `response_format` parameter\n",
    "    response_format=ResponseFormat\n",
    ")\n",
    "```\n",
    "\n",
    "Prebuilt ReAct makes an additional LLM call at the end of the ReAct loop to produce a structured output response. Please see [this guide](../react-agent-structured-output) to learn about other  strategies for returning structured outputs from a tool-calling agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3889f-3c17-4fa1-bd2b-84114a2c7247",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required packages and set our API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a213e11a-5c62-4ddb-a707-490d91add383",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a1885c-04ab-4750-aefa-105891fddf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a00ce9",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c0f089-070c-4cd4-87e0-6c51f2477b82",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a154152-973e-4b5d-aa13-48c617744a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we initialize the model we want to use.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# For this tutorial we will use custom tool that returns pre-defined values for weather in two cities (NYC & SF)\n",
    "\n",
    "from typing import Literal\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "# Define the structured output schema\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    \"\"\"Respond to the user in this format.\"\"\"\n",
    "\n",
    "    conditions: str = Field(description=\"Weather conditions\")\n",
    "\n",
    "\n",
    "# Define the graph\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "graph = create_react_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    # specify the schema for the structured output using `response_format` parameter\n",
    "    response_format=WeatherResponse,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00407425-506d-4ffd-9c86-987921d8c844",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "Let's now test our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffff6c3-a4f5-47c9-b51d-97caaee85cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"What's the weather in NYC?\")]}\n",
    "response = graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e273a0-fbdb-4eee-89ca-580fbfb52daf",
   "metadata": {},
   "source": [
    "You can see that the agent output contains a `structured_response` key with the structured output conforming to the specified `WeatherResponse` schema, in addition to the message history under `messages` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300748d4-0ed2-470d-8dbc-7c14231e73b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeatherResponse(conditions='cloudy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e3487-2cec-44cf-9472-0a51eebeddff",
   "metadata": {},
   "source": [
    "### Customizing prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a608548d-77fc-4d7a-845c-32ae9ec0489a",
   "metadata": {},
   "source": [
    "You might need to further customize the second LLM call for the structured output generation and provide a system prompt. To do so, you can pass a tuple (prompt, schema):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1386f99-ffd1-4b36-86ec-cabb3357d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    # specify both the system prompt and the schema for the structured output\n",
    "    response_format=(\"Always return capitalized weather conditions\", WeatherResponse),\n",
    ")\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"What's the weather in NYC?\")]}\n",
    "response = graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f34991-b406-4fd2-a776-4dd03e3dc3dd",
   "metadata": {},
   "source": [
    "You can verify that the structured response now contains a capitalized value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba43a67f-127c-45e7-982c-a8210d97a3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeatherResponse(conditions='Cloudy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"structured_response\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
