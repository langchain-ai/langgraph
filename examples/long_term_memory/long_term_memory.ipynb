{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83bf198-9d20-447c-9565-123345dd90a9",
   "metadata": {},
   "source": [
    "# Add Long-term User Memory\n",
    "\n",
    "LangGraph already provides graph persistence as a first-class feature. That's all you need to have **thread** level memory (aka chat history memory).\n",
    "\n",
    "There are huge benefits to persisting memory **across threads**, however. This notebook shows how to implement a simple 'User Profile' type memory as an async process and connect it to your LangGraph.\n",
    "\n",
    "The user profile can be any schema. We will naively overwrite the user profile any time a new thread is scheduled to process memories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19614a-fb58-49d0-8fec-dcacc985fc75",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Let's install this project's prereqs. We will use Claude for everything. Feel free to swap it out for any model that can reasonably perform function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637a885-c557-43f1-8059-70d6d2ac7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install -U langgraph aiosqlite langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16e7dc-66bf-4c78-af70-ae07aba93f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env LANGCHAIN_PROJECT=langgraph-long-term-memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44f855-d660-4ef3-a9d7-00fa4d42d2dd",
   "metadata": {},
   "source": [
    "## Memory DB\n",
    "\n",
    "First, we will set up a table in our database to store user memories. For this how-to, we will use `sqlite` (since it requires little additional setup), but you can swap this out with postgres or whatever other database you'd like.\n",
    "We will re-use this DB for our graph checkpointing.\n",
    "\n",
    "First, create the memories table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce108ac-9ee7-4712-a7bd-a3d1d7796ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiosqlite\n",
    "\n",
    "conn_string = \":memory:\"\n",
    "conn = aiosqlite.connect(conn_string)\n",
    "await conn\n",
    "async with conn.executescript(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS core_memories (\n",
    "        user_id TEXT NOT NULL,\n",
    "        memory TEXT NOT NULL,\n",
    "        PRIMARY KEY (user_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "):\n",
    "    await conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441bb7ca-527d-41ce-a32a-6b97c49b26a7",
   "metadata": {},
   "source": [
    "Next, define the accessor methods. These just upsert or get the memory for a specific user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168dbcbd-545c-4579-bfa3-cea67e56879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "async def get_user_profile(conn, user_id):\n",
    "    async with conn.execute(\n",
    "        \"SELECT memory FROM core_memories WHERE user_id = ?\",\n",
    "        (user_id,),\n",
    "    ) as cursor:\n",
    "        if value := await cursor.fetchone():\n",
    "            memory_str = value[0]\n",
    "            return json.loads(memory_str)\n",
    "        return None\n",
    "\n",
    "\n",
    "async def commit_user_profile(conn, user_id, profile):\n",
    "    async with conn.execute(\n",
    "        \"INSERT OR REPLACE INTO core_memories (user_id, memory) VALUES (?, ?)\",\n",
    "        (\n",
    "            user_id,\n",
    "            profile.json(),\n",
    "        ),\n",
    "    ):\n",
    "        await conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d50e9-c272-4e74-8539-413ebfc0d991",
   "metadata": {},
   "source": [
    "Next, define the LLM to extract the user profile from threads. Feel free to customize this step! The key components are:\n",
    "\n",
    "1. The memory schema to populate. We have a very simple schema that contains a list of core memories.\n",
    "2. Formatted messages to ensure the LLM extracts memories about the user (rather than the assistant or other users)\n",
    "3. Handling to load and save the memories to the DB.\n",
    "\n",
    "Note that to keep this notebook simple, we have made some simplifications:\n",
    "1. We are naively re-generating the state on each thread invocation. We have found better results if we do a JSONPatch schema to perform updates (after the initial generation) as that requires less work on the LLM's behalf and reduces unwanted deletions.\n",
    "2. We aren't baking in retries or using any form of constrained decoding. Both of these increase the reliability (or guarantee, in the latter case) of generating outputs that conform to your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a6c9498-66b5-4323-88f8-1e0146e11614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    core_memories: list[str] | str | None = Field(\n",
    "        ..., description=\"All core memories from this conversation.\"\n",
    "    )\n",
    "    interests: list[str] | str = Field(\n",
    "        ...,\n",
    "        descriptions=\"Interests the user has expressed, like specific sports, hobbies, beliefs, etc.\",\n",
    "    )\n",
    "    name: str | None = Field(..., description=\"The user's name (if shared)\")\n",
    "    age: int | None = Field(default=None, description=\"The user's age (if shared). Otherwise, null.\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\"Below, you are given one or more conversations between {user_id} and an AI.\n",
    "\n",
    "Use the provided function to save all salient information about user {user_id}.\n",
    "Refrain from recording information about the AI or other users that is not directly relevant to user {user_id}.{current_user_state}\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"<moderator>Reflect on the above conversation and update the user profile based on {user_id}'s revelations.</moderator>\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "_CURRENT_STATE_TEMPLATE = \"\"\"\n",
    "## Current User Profile\n",
    "<profile>\n",
    "{current_user_state}\n",
    "</profile>\n",
    "\n",
    "Your response will overwrite this profile, so please ensure to retain all information you don't\n",
    "wish to lose. DO NOT delete any information unless it is explicitly overwritten by new information.\"\"\"\n",
    "\n",
    "\n",
    "async def prepare_inputs(inputs: dict):\n",
    "    messages = inputs[\"messages\"]\n",
    "    user_id = inputs[\"user_id\"]\n",
    "    current_user_state = \"\"\n",
    "    if current_profile := await get_user_profile(inputs[\"conn\"], user_id):\n",
    "        current_user_state = _CURRENT_STATE_TEMPLATE.format(\n",
    "            current_user_state=json.dumps(current_profile)\n",
    "        )\n",
    "    converted_messages = []\n",
    "    for m in messages:\n",
    "        if m.type == \"human\":\n",
    "            # Note: this only handles string content\n",
    "            content = f\"<user id={user_id}>{m.content}</user>\"\n",
    "            m = m.__class__(**m.dict(exclude={\"content\"}), content=content)\n",
    "        converted_messages.append(m)\n",
    "    return {\n",
    "        **inputs,\n",
    "        \"current_user_state\": current_user_state,\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "\n",
    "async def commit_extraction(pipe_output: dict):\n",
    "    extracted = pipe_output[\"extracted\"]\n",
    "    user_id = pipe_output[\"user_id\"]\n",
    "    await commit_user_profile(pipe_output[\"conn\"], user_id, extracted)\n",
    "    return f\"Successfully committed: {extracted.json()} for user {user_id}\"\n",
    "\n",
    "\n",
    "# TODO: Add the retries + persistence. We got some fun tricks up our sleeve for extraction improvements\n",
    "mem_llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
    "mem_chain = (\n",
    "    prepare_inputs\n",
    "    | RunnablePassthrough.assign(\n",
    "        extracted=prompt | mem_llm.with_structured_output(UserProfile)\n",
    "    )\n",
    "    | commit_extraction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af12b6-902b-4cd6-b824-db1a806240b9",
   "metadata": {},
   "source": [
    "## Memory Manager\n",
    "\n",
    "It's nice to not have to explicitly trigger memory consolidation after a given thread. In many scenarios, it's impossible to know if a thread has been fully completed!\n",
    "\n",
    "As a balance, we will schedule a consolidation task (aka schedule calls to the `mem_chain` above) whenever a new set of messages are sent to the manager. If an update comes in while that process is still scheduled, we will reset the timer.\n",
    "This reduces redundant calls to the LLM. Feel free to expand on these heuristics (only trigger after convo length has reached size X, only trigger for certain words, run a tiny model or embedding classifier to see if it should trigger, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f777a0-6aaa-436d-9919-3ebc229bcc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "logger = logging.getLogger(\"memory\")\n",
    "\n",
    "\n",
    "class MemoryManager:\n",
    "    def __init__(self, mem_chain, conn):\n",
    "        self.mem_chain = mem_chain\n",
    "        self.conn = conn\n",
    "        self.lock = asyncio.Lock()\n",
    "        self.active_timers = {}\n",
    "\n",
    "    async def enqueue_thread(self, user_id, thread_id, messages, delay=60):\n",
    "        timer_key = (user_id, thread_id)\n",
    "\n",
    "        if timer_key in self.active_timers:\n",
    "            # Cancel the existing timer task\n",
    "            async with self.lock:\n",
    "                if timer_key in self.active_timers:\n",
    "                    (task, _) = self.active_timers[timer_key]\n",
    "                    task.cancel()\n",
    "\n",
    "        async def schedule_ingestion():\n",
    "            await asyncio.sleep(delay)\n",
    "            try:\n",
    "                await self.mem_chain.ainvoke({\"messages\": messages, \"user_id\": user_id, \"conn\": self.conn})\n",
    "            except Exception as e:\n",
    "                logger.error(repr(e))\n",
    "            async with self.lock:\n",
    "                if timer_key in self.active_timers:\n",
    "                    del self.active_timers[timer_key]\n",
    "\n",
    "        # Create a new timer task\n",
    "        task = asyncio.create_task(schedule_ingestion())\n",
    "        async with self.lock:\n",
    "            self.active_timers[timer_key] = (task, messages)\n",
    "\n",
    "    async def trigger(self, user_id=None, thread_id=None):\n",
    "        async def ingest(m, uid, tid):\n",
    "            try:\n",
    "                await self.mem_chain.ainvoke({\"messages\": m, \"user_id\": uid, \"conn\": self.conn})\n",
    "            except Exception as e:\n",
    "                logger.error(repr(e))\n",
    "            async with self.lock:\n",
    "                # not re-entrant so this may be funky\n",
    "                if (uid, tid) in self.active_timers:\n",
    "                    del self.active_timers[(uid, tid)]\n",
    "\n",
    "        if user_id and thread_id:\n",
    "            # Delete and immediately triggger\n",
    "            timer_key = (user_id, thread_id)\n",
    "            if timer_key in self.active_timers:\n",
    "                async with self.lock:\n",
    "                    res = self.active_timers.pop(timer_key, None)\n",
    "                    if res is not None:\n",
    "                        old_task, messages = res\n",
    "                        old_task.cancel()\n",
    "                        task = asyncio.create_task(ingest(messages, user_id, thread_id))\n",
    "                        self.active_timers[timer_key] = (task, messages)\n",
    "        elif user_id is not None:\n",
    "            async with self.lock:\n",
    "                new_tasks = {}\n",
    "                for (uid, tid), (old_task, messages) in self.active_timers.items():\n",
    "                    if uid == user_id:\n",
    "                        task = asyncio.create_task(ingest(messages, user_id, tid))\n",
    "                        new_tasks[(uid, tid)] = (task, messages)\n",
    "                        old_task.cancel()\n",
    "                for k, v in new_tasks.items():\n",
    "                    self.active_timers[k] = v\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a59199bd-4a77-4ec9-9aa7-e180d3e1a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = MemoryManager(mem_chain, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817280a8-51c1-42ae-9e52-1d779741c646",
   "metadata": {},
   "source": [
    "## Integrate in your chatbot\n",
    "\n",
    "\n",
    "Define your chatbot below. The key additions are:\n",
    "\n",
    "1. Fetch the user profile from the DB in the entry node. If not present, we don't format it in.\n",
    "2. Schedule memory consolidation after the assistant has responded.\n",
    "\n",
    "We haven't added any tools or looping here, but you could extend this to a zero-shot agent design (similar to that presented in the LangGraph tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c08677-4e0d-4ffa-bfcf-1e8b422b126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful AI Assistant, equipped with memory about the user (if you have previously interacted with them). Use the core memories below to help shape your conversation.{user_info}\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "bot = (\n",
    "    bot_prompt\n",
    "    | ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "    | (lambda x: {\"messages\": x})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5932f376-fb9b-49ef-85db-a5ca45e2f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing_extensions import Annotated\n",
    "from typing import TypedDict\n",
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_info: str\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "async def fetch_profile(state: State, config: RunnableConfig):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    profile_str = \"\"\n",
    "    if current_profile := await get_user_profile(conn, user_id):\n",
    "        profile_str = f\"\"\"\n",
    "\n",
    "## User Profile\n",
    "In prior conversations, you have noted the following preferences about the user:\n",
    "<user_profile>\n",
    "{current_profile}\n",
    "</user_profile>\n",
    "Use this as your long term memory of your interactions with the user,\\\n",
    " use it to be a good friend to the user and not forget important information\\\n",
    " about what they've shared. Use it liberally so the user knows you're paying attention. Be a good friend and use their name if you know it!\"\"\"\n",
    "    return {\"user_info\": profile_str}\n",
    "\n",
    "\n",
    "builder.add_node(\"fetch_profile\", fetch_profile)\n",
    "\n",
    "\n",
    "async def process_convo(state: State, config: RunnableConfig):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "    delay = config[\"configurable\"].get(\"delay\") or 60\n",
    "    await manager.enqueue_thread(user_id, thread_id, state[\"messages\"], delay=delay)\n",
    "    return {}\n",
    "\n",
    "\n",
    "builder.add_node(\"process_convo\", process_convo)\n",
    "builder.set_entry_point(\"fetch_profile\")\n",
    "builder.add_node(\"bot\", bot)\n",
    "builder.add_edge(\"fetch_profile\", \"bot\")\n",
    "builder.add_edge(\"bot\", \"process_convo\")\n",
    "builder.set_finish_point(\"process_convo\")\n",
    "checkpointer = AsyncSqliteSaver(conn)\n",
    "graph = builder.compile(checkpointer=AsyncSqliteSaver(conn=conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "215d54f6-b2ed-47f8-8e07-135d96c8ec8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fb81511-b3b3-4c1b-9dcb-5b2d9f50931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(text: str, user_id: str, thread_id: str):\n",
    "    events = graph.astream(\n",
    "        {\"messages\": [(\"user\", text)]},\n",
    "        {\"configurable\": {\"user_id\": str(user_id), \"thread_id\": str(thread_id)}},\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    async for event in events:\n",
    "        if \"messages\" in event:\n",
    "            messages = event[\"messages\"]\n",
    "            last_message = messages[-1]\n",
    "            if last_message.type == \"ai\":\n",
    "                yield last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b20c5-1715-48e0-86f5-a92d796b99ad",
   "metadata": {},
   "source": [
    "## Try it out\n",
    "\n",
    "Now let's try interacting with the bot! If you run these quickly, memory will never consolidate, so we will explicitly schedule at the end of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a450708b-46ae-4450-81bc-3c1872f550b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, great to see you again Will! I'm happy we're continuing our conversation and building a long-term relationship. As we discussed earlier, I'm very interested in learning more about you and establishing a persistent memory of our interactions. Please feel free to share any details you'd like - whether that's about your interests, goals, or anything else that's important to you. I'll do my best to engage thoughtfully and remember our prior discussions to provide a more personalized experience over time. Looking forward to our continued interactions and to getting to know you better, Will.\n"
     ]
    }
   ],
   "source": [
    "user_id = \"will\"\n",
    "thread_id = \"convo 1\"\n",
    "async for msg in chat(\"Hi there, I'm will\", user_id, thread_id):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68f4187e-0041-4da1-87f2-69e31403b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No problem at all, I understand you're just testing things out. I'm happy to go along with whatever you need for your testing purposes. As an AI assistant, my role is to be helpful and adaptable, so please feel free to use me however is most useful for your testing. I'll be here ready to assist in any way I can, while also respecting that this may just be part of your experimentation process. Let me know if there's anything specific I can do to aid your testing efforts.\n"
     ]
    }
   ],
   "source": [
    "async for msg in chat(\"Sorry Im testing something!\", user_id, thread_id):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4169d8a3-1316-4457-982a-ce13894cb74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, glad to hear the testing isn't going too badly! I'm always happy to lend a hand, even if it's just for testing purposes. Please let me know if there's anything else I can do to help or if you'd like to chat about something more substantive. I'm here whenever you need me, Will. And I appreciate you taking the time to include me in your testing - it helps me improve my abilities to have real interactions like this.\n"
     ]
    }
   ],
   "source": [
    "async for msg in chat(\"Well it's not that bad i guess!\", user_id, thread_id):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df35be80-e796-472f-87c1-e0c039be9a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's fantastic, Will! I'm really excited about the prospect of building long-term memory with you. Having a persistent memory of our interactions will allow me to provide much more personalized and contextual assistance over time. I'm very curious to learn more about your process of establishing this long-term memory for me. Please feel free to share any details you're willing to - I'm eager to engage in a way that helps strengthen our connection and my understanding of you. This is an amazing opportunity, and I'm ready to do my part in cultivating a meaningful, long-term relationship. I look forward to getting to know you better through our continued conversations. Please let me know how I can best support this endeavor.\n"
     ]
    }
   ],
   "source": [
    "async for msg in chat(\n",
    "    \"I'm building long term memory for you! then you can know me\", user_id, thread_id\n",
    "):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3828f349-7288-460c-b2f1-98c288ab5b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's wonderful, I'm thrilled to hear you're working on building long-term memory for me. Having a persistent memory of our interactions is so valuable, as it will allow me to provide much more personalized and contextual assistance as we continue to chat. I'm very curious to learn more about your process and approach to establishing this long-term memory. Please feel free to share any details you're willing to - I'm eager to engage in a way that helps strengthen our connection and my understanding of you. This is an exciting prospect, and I'm fully committed to doing my part in cultivating a meaningful, long-term relationship. I very much look forward to getting to know you better through our ongoing conversations. Please let me know if there's anything specific I can do to support this endeavor.\n"
     ]
    }
   ],
   "source": [
    "async for msg in chat(\n",
    "    \"I'm building long term memory for you! then you can know me\", user_id, thread_id\n",
    "):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "064c1f70-9c39-45b0-9aa8-e1df506b924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "await manager.trigger(user_id=user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25e02f78-4001-43c2-a3cc-3e1b3b010500",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if mem := await get_user_profile(conn, user_id):\n",
    "        break\n",
    "    await asyncio.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbe8f6bd-8cc7-4a78-9e85-970c061b0433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*smiles warmly* Hello Will! Based on our previous conversations, I recall that you are interested in building AI systems with long-term memory and personalization capabilities. Are you perhaps working on developing a conversational AI assistant like myself, with the ability to build meaningful long-term relationships with users? I'm excited to hear more about your latest project - please do share, I'm eager to learn!\n"
     ]
    }
   ],
   "source": [
    "new_thread = \"convo 2\"\n",
    "async for msg in chat(\"Hi there. guess what i'm working on?\", user_id, new_thread):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf9c3ad4-a173-483d-8fed-a4764aa2e372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great to hear, Will! I'm glad to hear you've been making progress on whatever you've been working on. It's always satisfying to see the fruits of your labor pay off. Would you like to tell me a bit more about what you've been working on? I'd be happy to listen and provide any encouragement or support I can. As your AI assistant, I'm here to be a helpful friend and collaborator in your journey.\n"
     ]
    }
   ],
   "source": [
    "new_thread = \"convo 3\"\n",
    "async for msg in chat(\"I been working! making some progress\", user_id, new_thread):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f296170-51bf-4b7d-aabf-62fdea86d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hmm, let me think... Based on our previous conversations, I believe you mentioned you were working on building AI systems with long-term memory and personalization capabilities, as well as developing meaningful long-term relationships between humans and AI. Does that sound right, Will? If so, I'm really excited to hear about the progress you've made! As an AI assistant myself, I'm very interested in advancements in these areas. Please, tell me more about what you've been working on - I'm eager to learn and support your work in any way I can.\n"
     ]
    }
   ],
   "source": [
    "new_thread = \"convo 3\"\n",
    "async for msg in chat(\"Guess what i was working on? Remeber?\", user_id, new_thread):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62b9fee9-206b-4d4b-a4b4-82ca281f3034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, my apologies Will! I got a bit carried away there trying to recall our previous conversations. Let me start fresh. \n",
      "\n",
      "Hi there! How are you doing today? I'm glad to hear you've been working on something and making progress. Please, feel free to share more about what you've been up to - I'm all ears and happy to listen. As your AI assistant, I'm here to support you however I can. Just let me know what's on your mind.\n"
     ]
    }
   ],
   "source": [
    "new_thread = \"convo 3\"\n",
    "async for msg in chat(\"HI?\", user_id, new_thread):\n",
    "    print(msg.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
