{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53",
   "metadata": {},
   "source": [
    "# How to create a custom checkpointer using Postgres\n",
    "\n",
    "When creating LangGraph agents, you can also set them up so that they persist their state. This allows you to do things like interact with an agent multiple times and have it remember previous interactions.\n",
    "\n",
    "This example shows how to use `Postgres` as the backend for persisting checkpoint state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc5cc5f-89fa-4d7a-9f2b-5b099feb6ecc",
   "metadata": {},
   "source": [
    "## Checkpointer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faadfb1b-cebe-4dcf-82fd-34044c380bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U psycopg psycopg-pool langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35dba8e-5562-4803-ad80-160f53592dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation of a langgraph checkpoint saver using Postgres.\"\"\"\n",
    "from contextlib import asynccontextmanager, contextmanager\n",
    "from typing import Any, AsyncGenerator, AsyncIterator, Generator, Optional, Union, Tuple, List\n",
    "\n",
    "import psycopg\n",
    "from psycopg.types.json import Jsonb\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint import BaseCheckpointSaver\n",
    "from langgraph.serde.jsonplus import JsonPlusSerializer\n",
    "from langgraph.checkpoint.base import Checkpoint, CheckpointMetadata, CheckpointTuple\n",
    "from psycopg_pool import AsyncConnectionPool, ConnectionPool\n",
    "\n",
    "\n",
    "class JsonAndBinarySerializer(JsonPlusSerializer):\n",
    "    def _default(self, obj):\n",
    "        if isinstance(obj, (bytes, bytearray)):\n",
    "            return self._encode_constructor_args(\n",
    "                obj.__class__, method=\"fromhex\", args=[obj.hex()]\n",
    "            )\n",
    "        return super()._default(obj)\n",
    "\n",
    "    def dumps(self, obj: Any) -> tuple[str, bytes]:\n",
    "        if isinstance(obj, bytes):\n",
    "            return \"bytes\", obj\n",
    "        elif isinstance(obj, bytearray):\n",
    "            return \"bytearray\", obj\n",
    "\n",
    "        return \"json\", super().dumps(obj)\n",
    "\n",
    "    def loads(self, s: tuple[str, bytes]) -> Any:\n",
    "        if s[0] == \"bytes\":\n",
    "            return s[1]\n",
    "        elif s[0] == \"bytearray\":\n",
    "            return bytearray(s[1])\n",
    "        elif s[0] == \"json\":\n",
    "            return super().loads(s[1])\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown serialization type: {s[0]}\")\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def _get_sync_connection(\n",
    "    connection: Union[psycopg.Connection, ConnectionPool, None],\n",
    ") -> Generator[psycopg.Connection, None, None]:\n",
    "    \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "    if isinstance(connection, psycopg.Connection):\n",
    "        yield connection\n",
    "    elif isinstance(connection, ConnectionPool):\n",
    "        with connection.connection() as conn:\n",
    "            yield conn\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid sync connection object. Please initialize the check pointer \"\n",
    "            f\"with an appropriate sync connection object. \"\n",
    "            f\"Got {type(connection)}.\"\n",
    "        )\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def _get_async_connection(\n",
    "    connection: Union[psycopg.AsyncConnection, AsyncConnectionPool, None],\n",
    ") -> AsyncGenerator[psycopg.AsyncConnection, None]:\n",
    "    \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "    if isinstance(connection, psycopg.AsyncConnection):\n",
    "        yield connection\n",
    "    elif isinstance(connection, AsyncConnectionPool):\n",
    "        async with connection.connection() as conn:\n",
    "            yield conn\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid async connection object. Please initialize the check pointer \"\n",
    "            f\"with an appropriate async connection object. \"\n",
    "            f\"Got {type(connection)}.\"\n",
    "        )\n",
    "\n",
    "\n",
    "class PostgresSaver(BaseCheckpointSaver):\n",
    "    sync_connection: Optional[Union[psycopg.Connection, ConnectionPool]] = None\n",
    "    \"\"\"The synchronous connection or pool to the Postgres database.\n",
    "    \n",
    "    If providing a connection object, please ensure that the connection is open\n",
    "    and remember to close the connection when done.\n",
    "    \"\"\"\n",
    "    async_connection: Optional[\n",
    "        Union[psycopg.AsyncConnection, AsyncConnectionPool]\n",
    "    ] = None\n",
    "    \"\"\"The asynchronous connection or pool to the Postgres database.\n",
    "    \n",
    "    If providing a connection object, please ensure that the connection is open\n",
    "    and remember to close the connection when done.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sync_connection: Optional[Union[psycopg.Connection, ConnectionPool]] = None,\n",
    "        async_connection: Optional[\n",
    "            Union[psycopg.AsyncConnection, AsyncConnectionPool]\n",
    "        ] = None\n",
    "        \n",
    "    ):\n",
    "        super().__init__(serde=JsonPlusSerializer())\n",
    "        self.sync_connection = sync_connection\n",
    "        self.async_connection = async_connection\n",
    "\n",
    "    @contextmanager\n",
    "    def _get_sync_connection(self) -> Generator[psycopg.Connection, None, None]:\n",
    "        \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "        with _get_sync_connection(self.sync_connection) as connection:\n",
    "            yield connection\n",
    "\n",
    "    @asynccontextmanager\n",
    "    async def _get_async_connection(\n",
    "        self,\n",
    "    ) -> AsyncGenerator[psycopg.AsyncConnection, None]:\n",
    "        \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "        async with _get_async_connection(self.async_connection) as connection:\n",
    "            yield connection\n",
    "\n",
    "    @staticmethod\n",
    "    def create_tables(connection: Union[psycopg.Connection, ConnectionPool], /) -> None:\n",
    "        \"\"\"Create the schema for the checkpoint saver.\"\"\"\n",
    "        with _get_sync_connection(connection) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS checkpoints (\n",
    "                        thread_id TEXT NOT NULL,\n",
    "                        thread_ts TEXT NOT NULL,\n",
    "                        parent_ts TEXT,\n",
    "                        checkpoint BYTEA NOT NULL,\n",
    "                        metadata BYTEA NOT NULL,\n",
    "                        PRIMARY KEY (thread_id, thread_ts)\n",
    "                    );\n",
    "                    \"\"\"\n",
    "                )\n",
    "\n",
    "    @staticmethod\n",
    "    async def acreate_tables(\n",
    "        connection: Union[psycopg.AsyncConnection, AsyncConnectionPool], /\n",
    "    ) -> None:\n",
    "        \"\"\"Create the schema for the checkpoint saver.\"\"\"\n",
    "        async with _get_async_connection(connection) as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                await cur.execute(\n",
    "                    \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS checkpoints (\n",
    "                        thread_id TEXT NOT NULL,\n",
    "                        thread_ts TEXT NOT NULL,\n",
    "                        parent_ts TEXT,\n",
    "                        checkpoint BYTEA NOT NULL,\n",
    "                        metadata BYTEA NOT NULL,\n",
    "                        PRIMARY KEY (thread_id, thread_ts)\n",
    "                    );\n",
    "                    \"\"\"\n",
    "                )\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_tables(connection: psycopg.Connection, /) -> None:\n",
    "        \"\"\"Drop the table for the checkpoint saver.\"\"\"\n",
    "        with connection.cursor() as cur:\n",
    "            cur.execute(\"DROP TABLE IF EXISTS checkpoints;\")\n",
    "\n",
    "    @staticmethod\n",
    "    async def adrop_tables(connection: psycopg.AsyncConnection, /) -> None:\n",
    "        \"\"\"Drop the table for the checkpoint saver.\"\"\"\n",
    "        async with connection.cursor() as cur:\n",
    "            await cur.execute(\"DROP TABLE IF EXISTS checkpoints;\")\n",
    "\n",
    "    def put(self, config: RunnableConfig, checkpoint: Checkpoint, metadata: CheckpointMetadata) -> RunnableConfig:\n",
    "        \"\"\"Put the checkpoint for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "            checkpoint: The checkpoint to persist.\n",
    "        Returns:\n",
    "            The RunnableConfig that describes the checkpoint that was just created.\n",
    "            It'll contain the `thread_id` and `thread_ts` of the checkpoint.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO checkpoints \n",
    "                        (thread_id, thread_ts, parent_ts, checkpoint, metadata)\n",
    "                    VALUES \n",
    "                        (%s, %s, %s, %s, %s)\n",
    "                    ON CONFLICT (thread_id, thread_ts)\n",
    "                    DO UPDATE SET checkpoint = EXCLUDED.checkpoint,\n",
    "                                  metadata = EXCLUDED.metadata;\n",
    "                    \"\"\",\n",
    "                    (\n",
    "                        thread_id,\n",
    "                        checkpoint[\"ts\"],\n",
    "                        parent_ts if parent_ts else None,\n",
    "                        self.serde.dumps(checkpoint),\n",
    "                        self.serde.dumps(metadata),\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"thread_ts\": checkpoint[\"ts\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    async def aput(\n",
    "        self, config: RunnableConfig, checkpoint: Checkpoint, metadata: CheckpointMetadata\n",
    "    ) -> RunnableConfig:\n",
    "        \"\"\"Put the checkpoint for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "            checkpoint: The checkpoint to persist.\n",
    "        Returns:\n",
    "            The RunnableConfig that describes the checkpoint that was just created.\n",
    "            It'll contain the `thread_id` and `thread_ts` of the checkpoint.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                await cur.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO checkpoints \n",
    "                        (thread_id, thread_ts, parent_ts, checkpoint, metadata)\n",
    "                    VALUES \n",
    "                        (%s, %s, %s, %s, %s)\n",
    "                    ON CONFLICT (thread_id, thread_ts)\n",
    "                    DO UPDATE SET checkpoint = EXCLUDED.checkpoint,\n",
    "                                  metadata = EXCLUDED.metadata;\n",
    "                    \"\"\",\n",
    "                    (\n",
    "                        thread_id,\n",
    "                        checkpoint[\"ts\"],\n",
    "                        parent_ts if parent_ts else None,\n",
    "                        self.serde.dumps(checkpoint),\n",
    "                        self.serde.dumps(metadata),\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"thread_ts\": checkpoint[\"ts\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def list(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        *,\n",
    "        filter: Optional[dict[str, Any]] = None,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> Generator[CheckpointTuple, None, None]:\n",
    "        \"\"\"Get all the checkpoints for the given configuration.\"\"\"\n",
    "        where, args = self._search_where(config, filter, before)\n",
    "        query = (\n",
    "            f\"\"\"\n",
    "            SELECT checkpoint, metadata, thread_ts, parent_ts\n",
    "            FROM checkpoints\n",
    "            {where}\n",
    "            ORDER BY thread_ts DESC\n",
    "            \"\"\"\n",
    "        )\n",
    "        if limit:\n",
    "            query += f\" LIMIT {limit}\"\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "                cur.execute(query, tuple(args))\n",
    "                for value in cur:\n",
    "                    checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                    yield CheckpointTuple(\n",
    "                        config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        },\n",
    "                        checkpoint=self.serde.loads(checkpoint),\n",
    "                        metadata=self.serde.loads(metadata),\n",
    "                        parent_config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        }\n",
    "                        if parent_ts\n",
    "                        else None,\n",
    "                    )\n",
    "\n",
    "    async def alist(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        *,\n",
    "        filter: Optional[dict[str, Any]] = None,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> AsyncIterator[CheckpointTuple]:\n",
    "        \"\"\"Get all the checkpoints for the given configuration.\"\"\"\n",
    "        where, args = self._search_where(config, filter, before)\n",
    "        query = (\n",
    "            f\"\"\"\n",
    "            SELECT checkpoint, metadata, thread_ts, parent_ts\n",
    "            FROM checkpoints\n",
    "            {where}\n",
    "            ORDER BY thread_ts DESC\n",
    "            \"\"\"\n",
    "        )\n",
    "        if limit:\n",
    "            query += f\" LIMIT {limit}\"\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "                await cur.execute(query, tuple(args))\n",
    "                async for value in cur:\n",
    "                    checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                    yield CheckpointTuple(\n",
    "                        config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        },\n",
    "                        checkpoint=self.serde.loads(checkpoint),\n",
    "                        metadata=self.serde.loads(metadata),\n",
    "                        parent_config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        }\n",
    "                        if parent_ts\n",
    "                        else None,\n",
    "                    )\n",
    "\n",
    "    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Get the checkpoint tuple for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "        Returns:\n",
    "            The checkpoint tuple for the given configuration if it exists,\n",
    "            otherwise None.\n",
    "            If thread_ts is None, the latest checkpoint is returned if it exists.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                if thread_ts:\n",
    "                    cur.execute(\n",
    "                        \"SELECT checkpoint, metadata, thread_ts, parent_ts \"\n",
    "                        \"FROM checkpoints \"\n",
    "                        \"WHERE thread_id = %(thread_id)s AND thread_ts = %(thread_ts)s\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"thread_ts\": thread_ts,\n",
    "                        },\n",
    "                    )\n",
    "                    value = cur.fetchone()\n",
    "                    if value:\n",
    "                        checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                    return CheckpointTuple(\n",
    "                            config=config,\n",
    "                            checkpoint=self.serde.loads(checkpoint),\n",
    "                            metadata=self.serde.loads(metadata),\n",
    "                            parent_config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": thread_ts,\n",
    "                                }\n",
    "                            }\n",
    "                            if thread_ts\n",
    "                            else None,\n",
    "                        )\n",
    "                else:\n",
    "                    cur.execute(\n",
    "                        \"SELECT checkpoint, metadata, thread_ts, parent_ts \"\n",
    "                        \"FROM checkpoints \"\n",
    "                        \"WHERE thread_id = %(thread_id)s \"\n",
    "                        \"ORDER BY thread_ts DESC LIMIT 1\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                        },\n",
    "                    )\n",
    "                    value = cur.fetchone()\n",
    "                    if value:\n",
    "                        checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                        return CheckpointTuple(\n",
    "                            config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": thread_ts,\n",
    "                                }\n",
    "                            },\n",
    "                            checkpoint=self.serde.loads(checkpoint),\n",
    "                            metadata=self.serde.loads(metadata),\n",
    "                            parent_config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": parent_ts,\n",
    "                                }\n",
    "                            }\n",
    "                            if parent_ts\n",
    "                            else None,\n",
    "                        )\n",
    "        return None\n",
    "\n",
    "    async def aget_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Get the checkpoint tuple for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "        Returns:\n",
    "            The checkpoint tuple for the given configuration if it exists,\n",
    "            otherwise None.\n",
    "            If thread_ts is None, the latest checkpoint is returned if it exists.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                if thread_ts:\n",
    "                    await cur.execute(\n",
    "                        \"SELECT checkpoint, metadata, thread_ts, parent_ts \"\n",
    "                        \"FROM checkpoints \"\n",
    "                        \"WHERE thread_id = %(thread_id)s AND thread_ts = %(thread_ts)s\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"thread_ts\": thread_ts,\n",
    "                        },\n",
    "                    )\n",
    "                    value = await cur.fetchone()\n",
    "                    if value:\n",
    "                        checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                    return CheckpointTuple(\n",
    "                            config=config,\n",
    "                            checkpoint=self.serde.loads(checkpoint),\n",
    "                            metadata=self.serde.loads(metadata),\n",
    "                            parent_config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": thread_ts,\n",
    "                                }\n",
    "                            }\n",
    "                            if thread_ts\n",
    "                            else None,\n",
    "                        )\n",
    "                else:\n",
    "                    await cur.execute(\n",
    "                        \"SELECT checkpoint, metadata, thread_ts, parent_ts \"\n",
    "                        \"FROM checkpoints \"\n",
    "                        \"WHERE thread_id = %(thread_id)s \"\n",
    "                        \"ORDER BY thread_ts DESC LIMIT 1\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                        },\n",
    "                    )\n",
    "                    value = await cur.fetchone()\n",
    "                    if value:\n",
    "                        checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                        return CheckpointTuple(\n",
    "                            config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": thread_ts,\n",
    "                                }\n",
    "                            },\n",
    "                            checkpoint=self.serde.loads(checkpoint),\n",
    "                            metadata=self.serde.loads(metadata),\n",
    "                            parent_config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": parent_ts,\n",
    "                                }\n",
    "                            }\n",
    "                            if parent_ts\n",
    "                            else None,\n",
    "                        )\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _search_where(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        filter: Optional[dict[str, Any]] = None,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "    ) -> Tuple[str, List[Any]]:\n",
    "        \"\"\"Return WHERE clause predicates for given config, filter, and before parameters.\n",
    "        Args:\n",
    "            config (Optional[RunnableConfig]): The config to use for filtering.\n",
    "            filter (Optional[Dict[str, Any]]): Additional filtering criteria.\n",
    "            before (Optional[RunnableConfig]): A config to limit results before a certain timestamp.\n",
    "        Returns:\n",
    "            Tuple[str, Sequence[Any]]: A tuple containing the WHERE clause and parameter values.\n",
    "        \"\"\"\n",
    "        wheres = []\n",
    "        param_values = []\n",
    "\n",
    "        # Add predicate for config\n",
    "        if config is not None:\n",
    "            wheres.append(\"thread_id = %s \")\n",
    "            param_values.append(config[\"configurable\"][\"thread_id\"])\n",
    "\n",
    "        if filter:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        # Add predicate for limiting results before a certain timestamp\n",
    "        if before is not None:\n",
    "            wheres.append(\"thread_ts < %s\")\n",
    "            param_values.append(before[\"configurable\"][\"thread_ts\"])\n",
    "\n",
    "        where_clause = \"WHERE \" + \" AND \".join(wheres) if wheres else \"\"\n",
    "        return where_clause, param_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456fa19c-93a5-4750-a410-f2d810b964ad",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca9aafb-a155-407a-8036-682a2f1297d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26b3204-cca2-414c-800e-7e09032445ae",
   "metadata": {},
   "source": [
    "## Setup model and tools for the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5213193-5a7d-43e7-aeba-fe732bb1cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is all that's needed for the agent.py\n",
    "from typing import Literal\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9342c62-dbb4-40f6-9271-7393f1ca48c4",
   "metadata": {},
   "source": [
    "## Use sync connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9d13b1-9d72-48a0-b63a-adc062c06c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_URI = \"postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39fc712-9e1c-4831-9077-dd07b0c13594",
   "metadata": {},
   "source": [
    "### With a connection pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2657c1c4-d8a5-4fe3-8f77-95415a98ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg_pool import ConnectionPool\n",
    "\n",
    "pool = ConnectionPool(\n",
    "    # Example configuration\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    ")\n",
    "\n",
    "checkpointer = PostgresSaver(\n",
    "    sync_connection=pool\n",
    ")\n",
    "checkpointer.create_tables(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d388241-de57-4b4e-af7b-eb1081fb8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e0e7ec-a675-470b-9270-e4bdc59d4a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's the weather in sf\", id='901969c5-06e7-40bc-b100-d5d49b3d8437'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_tfxPOypDP4eKMMpt9aFaWhfl', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d576307f90', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1d7366cb-21ae-46b6-9810-1c96bd08b767-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_tfxPOypDP4eKMMpt9aFaWhfl'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}),\n",
       "  ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='a9bf18ff-f105-4a85-b079-fccc830b39d6', tool_call_id='call_tfxPOypDP4eKMMpt9aFaWhfl'),\n",
       "  AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d576307f90', 'finish_reason': 'stop', 'logprobs': None}, id='run-a34191ae-92ec-432e-9165-fdbca8d22e70-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96efd8b2-97c9-4207-83b2-00131723a75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v': 1,\n",
       " 'ts': '2024-06-26T20:12:34.761278+00:00',\n",
       " 'id': '1ef33f86-d21c-6f16-8003-4d8eecf3b1c1',\n",
       " 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='901969c5-06e7-40bc-b100-d5d49b3d8437'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_tfxPOypDP4eKMMpt9aFaWhfl', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d576307f90', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1d7366cb-21ae-46b6-9810-1c96bd08b767-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_tfxPOypDP4eKMMpt9aFaWhfl'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}),\n",
       "   ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='a9bf18ff-f105-4a85-b079-fccc830b39d6', tool_call_id='call_tfxPOypDP4eKMMpt9aFaWhfl'),\n",
       "   AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d576307f90', 'finish_reason': 'stop', 'logprobs': None}, id='run-a34191ae-92ec-432e-9165-fdbca8d22e70-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})],\n",
       "  'agent': 'agent'},\n",
       " 'channel_versions': {'__start__': 2,\n",
       "  'messages': 5,\n",
       "  'start:agent': 3,\n",
       "  'agent': 5,\n",
       "  'branch:agent:should_continue:tools': 4,\n",
       "  'tools': 5},\n",
       " 'versions_seen': {'__start__': {'__start__': 1},\n",
       "  'agent': {'start:agent': 3, 'tools': 4},\n",
       "  'tools': {'branch:agent:should_continue:tools': 3}},\n",
       " 'pending_sends': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer.get(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c95c7-e392-4819-bd71-f29e91c68df3",
   "metadata": {},
   "source": [
    "### With a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180d6daf-8fa7-4608-bd2e-bfbf44ed5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg import Connection\n",
    "\n",
    "with Connection.connect(DB_URI) as conn:\n",
    "    checkpointer = PostgresSaver(\n",
    "        sync_connection=conn\n",
    "    )\n",
    "\n",
    "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "    res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)\n",
    "\n",
    "    checkpoint_tuple = checkpointer.get_tuple(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "613d0bbc-0e38-45c4-aace-1f6f7ae27c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CheckpointTuple(config={'configurable': {'thread_id': '2', 'thread_ts': '2024-06-26T20:12:35.934120+00:00'}}, checkpoint={'v': 1, 'ts': '2024-06-26T20:12:35.934120+00:00', 'id': '1ef33f86-dd4c-656c-8003-a2842c986615', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='eaed5136-89f4-4869-ba72-8fba6a1ddbae'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_MEMwvvJ2zdYlHB8N0dziVo8A', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d576307f90', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cf8111c7-7a04-4a9e-94c6-6721b36c9e96-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_MEMwvvJ2zdYlHB8N0dziVo8A'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}), ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='43541937-4544-47cb-9c74-3aea2d69b521', tool_call_id='call_MEMwvvJ2zdYlHB8N0dziVo8A'), AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'stop', 'logprobs': None}, id='run-9182e09b-2586-49bc-bede-11c8d20ff9f4-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__start__': {'__start__': 1}, 'agent': {'start:agent': 3, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 3, 'writes': {'agent': {'messages': [AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'stop', 'logprobs': None}, id='run-9182e09b-2586-49bc-bede-11c8d20ff9f4-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}}}, parent_config={'configurable': {'thread_id': '2', 'thread_ts': '1ef33f86-d868-6dde-8002-22adc60221a8'}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a47d3e-e588-48fc-a5d4-2145dff17e77",
   "metadata": {},
   "source": [
    "## Use async connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b6cf7-d8f7-4777-a48d-93b5855fe681",
   "metadata": {},
   "source": [
    "### With a connection pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20cea8b7-8f13-4dc7-a3c9-825040eb4c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vadymbarda/.virtualenvs/langgraph-postgres/lib/python3.11/site-packages/psycopg_pool/pool_async.py:138: RuntimeWarning: opening the async pool AsyncConnectionPool in the constructor is deprecated and will not be supported anymore in a future release. Please use `await pool.open()`, or use the pool as context manager using: `async with AsyncConnectionPool(...) as pool: `...\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from psycopg_pool import AsyncConnectionPool\n",
    "\n",
    "pool = AsyncConnectionPool(\n",
    "    # Example configuration\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    ")\n",
    "\n",
    "checkpointer = PostgresSaver(\n",
    "    async_connection=pool\n",
    ")\n",
    "await checkpointer.acreate_tables(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f889dce6-7ec1-4277-b8af-ace7811733fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "res = await graph.ainvoke({\"messages\": [(\"human\", \"what's the weather in nyc\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed58c722-1662-4ae2-9bb7-4872158a5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tuple = await checkpointer.aget_tuple(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0c42044-4de6-4742-8e00-fe295d50c95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CheckpointTuple(config={'configurable': {'thread_id': '3', 'thread_ts': '2024-06-26T20:12:37.056991+00:00'}}, checkpoint={'v': 1, 'ts': '2024-06-26T20:12:37.056991+00:00', 'id': '1ef33f86-e801-6be2-8003-3cbc2c2c7456', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='43fb8be7-928d-4d86-8ecd-6d96d9c0e9b6'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_eQQayuuq0BhQbVR6TRf41wZK', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e8902eaf-1720-443e-9d73-bf264a0213ea-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_eQQayuuq0BhQbVR6TRf41wZK'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='42171653-a463-4497-9493-6ae6a7beb3bc', tool_call_id='call_eQQayuuq0BhQbVR6TRf41wZK'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'stop', 'logprobs': None}, id='run-484394d7-8cf2-49ba-aa07-f24d7dd2070b-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__start__': {'__start__': 1}, 'agent': {'start:agent': 3, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 3, 'writes': {'agent': {'messages': [AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'stop', 'logprobs': None}, id='run-484394d7-8cf2-49ba-aa07-f24d7dd2070b-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})]}}}, parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef33f86-e390-67a2-8002-6e6136ffc685'}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56552584-9eb8-40df-a6a0-44151018b509",
   "metadata": {},
   "source": [
    "### Use connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b78bc-2f73-49ba-a2a4-47bce6fc49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg import AsyncConnection\n",
    "\n",
    "async with await AsyncConnection.connect(DB_URI) as conn:\n",
    "    checkpointer = PostgresSaver(\n",
    "        async_connection=conn\n",
    "    )\n",
    "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "    res = await graph.ainvoke({\"messages\": [(\"human\", \"what's the weather in nyc\")]}, config)\n",
    "    checkpoint_tuples = [c async for c in checkpointer.alist(config)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed1344-c923-4a46-b04e-cc3646737d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866da3d7-e1e8-455f-8d4f-bfa44cec67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-postgres",
   "language": "python",
   "name": "langgraph-postgres"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
