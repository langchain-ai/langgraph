{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pass custom LangSmith run ID for graph runs\n",
    "\n",
    "Debugging your graph runs can sometimes be difficult to do in your IDE or terminal. LangSmith lets you use trace data to debug, test, and monitor your LLM app â€” creating a virtuous data flywheel for improvement as your application evolves.\n",
    "\n",
    "In order to make it simple to find your graph run in LangSmith, you can pass in a custom `run_id` to the configuration of your graph invocation.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install our required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to set API keys for OpenAI (the LLM we will use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the graph\n",
    "\n",
    "For this example we will use the [prebuilt ReAct agent](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Literal\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# First we initialize the model we want to use.\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "\n",
    "# For this tutorial we will use custom tool that returns pre-defined values for weather in two cities (NYC & SF)\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "\n",
    "# Define the graph\n",
    "graph = create_react_agent(model, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your graph\n",
    "\n",
    "Now that we've defined our graph let's run it once and view the trace in LangSmith. In order for our trace to be easily accessible in LangSmith, we will pass in a custom `run_id` in the config.\n",
    "\n",
    "This assumes that you have set your `LANGCHAIN_API_KEY` environment variable.\n",
    "\n",
    "Note that you can also configure what project to trace to by setting the `LANGCHAIN_PROJECT` environment variable, by default runs will be traced to the `default` project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the weather in sf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_qpjGVrF4bNSJ5NarwjH2FTBJ)\n",
      " Call ID: call_qpjGVrF4bNSJ5NarwjH2FTBJ\n",
      "  Args:\n",
      "    city: sf\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's always sunny in sf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The weather in San Francisco is currently sunny.\n"
     ]
    }
   ],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "inputs = {\"messages\": [(\"user\", \"what is the weather in sf\")]}\n",
    "config = {\"configurable\": {\"run_id\":\"12345\"}}\n",
    "\n",
    "print_stream(graph.stream(inputs, config, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the trace in LangSmith\n",
    "\n",
    "Now that we've ran our graph, let's head over to LangSmith and view our trace. First click into the project that you traced to (in our case the default project). Next, let's add a filter to search for the run with the id (\"12345\") that we set above. You can do this by clicking the filter button which is near the top left of the project view (right under the \"Runs\" tab), you will then want to set a filter that looks something like this:\n",
    "\n",
    "![langsmith](langsmith_filter_run_id.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting the filter, you will see the corresponding graph run show up, and you can click on it to give you a more detailed view, which would look like this for the case above:\n",
    "\n",
    "![LangSmith Graph Trace](langsmith_graph_trace.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
