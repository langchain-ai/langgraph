{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ad077f-af4e-49b8-b549-fb3112299aa8",
   "metadata": {},
   "source": [
    "# Can Language Models Solve Olympiad Programming?\n",
    "\n",
    "In this tutorial, you will build a computing olympiad agent that leverages three complementary techniques to boost performance: **reflection**, **retrieval**, and **human-in-the-loop** collaboration. You will construct an agentic graph capable of answering programming questions of increasing difficulty.\n",
    "\n",
    "1. **Reflection**: In part 1, you will create a zero-shot tool calling agent and prompt it to reflect on the test case results to correct its initial errors. \n",
    "2. **Retrieval**: In Part 2, you will implement an initial retrieval step as \"episodic memory\" for the agent that retrieves high-quality few-shot examples from our corpora of programming problems to help solve the **bronze** level question.\n",
    "3. **Human-in-the-loop**: In part 3, you will use `interrupt_before` on an additional \"human\" node to guide the agent to a better answer.\n",
    "\n",
    "While LLMs are not yet capable of autonomously solving all these problems, through better agent design, you can create a system that far surpasses the capabilities of a basic ReAct agent at answering these questions. \n",
    "\n",
    "Your final agent graph will be structured like the diagram below:\n",
    "\n",
    "![diagram](./img/diagram.png)\n",
    "\n",
    "The techniques in this tutorial are all adapted from the paper \"Can Language Models Solve Olympiad Programming?\" by Quan Shi, Michael Tang, Karthik Narasimhan, and Shunyu Yao. You can check out their paper at the following link:\n",
    "\n",
    "[![arXiv](http://img.shields.io/badge/cs.CL-arXiv%3A2404.10952v1-B31B1B.svg)](https://arxiv.org/abs/2404.10952v1)\n",
    "\n",
    "\n",
    "\n",
    "Before diving in, let's set up our machine. This will involve installing dependencies, fetching the dataset, and defining a utility function.\n",
    "\n",
    "## Setup\n",
    "\n",
    "For this tutorial, we will need to install some dependencies, fetch the Olympiad dataset, and define a utility function to help run the candidate solutions to see if they pass the test cases.\n",
    "\n",
    "First, install the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686827a-8078-4fd4-af7a-638ca1362796",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langgraph langsmith langchain_anthropic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e542bb-a99e-44d3-8ebb-6a952dcbf2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _get_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_get_env(\"ANTHROPIC_API_KEY\")\n",
    "# Recommended\n",
    "_get_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ebbeb-c070-45d4-99ef-de33b53d447d",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "Fetch the USACO benchmark data using the util below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a0c7bd-512d-4e5b-ab43-1bc3b8c97fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import datasets\n",
    "import requests\n",
    "\n",
    "usaco_url = \"https://storage.googleapis.com/benchmarks-artifacts/usaco/usaco_sampled_with_tests.zip\"\n",
    "zip_path = \"usaco.zip\"\n",
    "extract_path = \"usaco_datasets\"\n",
    "\n",
    "response = requests.get(usaco_url)\n",
    "with open(zip_path, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "os.remove(zip_path)\n",
    "\n",
    "ds = datasets.load_from_disk(os.path.join(extract_path, \"usaco_v3_sampled_with_tests\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ad035-2c1a-4e31-93b4-58793d219bc9",
   "metadata": {},
   "source": [
    "#### Test Evaluation Utils\n",
    "\n",
    "We also need a way to evaluate our generated code. We will use this unsafe code execution program to run the generated code against our test cases.\n",
    "**Note:** The code below runs arbitrary code on your local machine! Proceed with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f9d037-121e-412f-857a-3e0ccc73892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import queue\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "multiprocessing.set_start_method(\"fork\", force=True)\n",
    "# WARNING\n",
    "# This program exists to execute untrusted model-generated code. Although\n",
    "# it is highly unlikely that model-generated code will do something overtly\n",
    "# malicious in response to this test suite, model-generated code may act\n",
    "# destructively due to a lack of model capability or alignment.\n",
    "# Users are strongly encouraged to sandbox this evaluation suite so that it\n",
    "# does not perform destructive actions on their host or network.\n",
    "# Proceed at your own risk:\n",
    "\n",
    "\n",
    "def exec_program(q, program, input_data, expected_output, timeout):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        process = subprocess.Popen(\n",
    "            [sys.executable, \"-c\", program],\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "        )\n",
    "        stdout, stderr = process.communicate(input=input_data, timeout=timeout)\n",
    "        if time.time() - start_time > timeout:\n",
    "            raise TimeoutError(\"Execution timed out.\")\n",
    "        if process.returncode != 0:\n",
    "            q.put(f\"failed: {stderr}\")\n",
    "        else:\n",
    "            if stdout.strip() == expected_output.strip():\n",
    "                q.put(\"passed\")\n",
    "            else:\n",
    "                q.put(f\"wrong answer. Expected '{expected_output}', got '{stdout}'\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        process.kill()\n",
    "        q.put(\"timed out\")\n",
    "    except Exception as e:\n",
    "        q.put(f\"failed: {traceback.format_exc()}\")\n",
    "\n",
    "\n",
    "def check_correctness(\n",
    "    program: str, input_data: str, expected_output: str, timeout: float\n",
    ") -> str:\n",
    "    q = multiprocessing.Queue()\n",
    "    process = multiprocessing.Process(\n",
    "        target=exec_program, args=(q, program, input_data, expected_output, timeout)\n",
    "    )\n",
    "    process.start()\n",
    "    process.join(timeout=timeout + 1)\n",
    "    if process.is_alive():\n",
    "        process.terminate()\n",
    "        process.join()\n",
    "        result = \"timed out\"\n",
    "    else:\n",
    "        try:\n",
    "            result = q.get_nowait()\n",
    "        except queue.Empty:\n",
    "            result = \"no result returned\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e799866-6334-4c3a-8d03-7b7b1cf730ab",
   "metadata": {},
   "source": [
    "Let's check an example program and output to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411cfc6a-d430-4642-8f48-2d6335430dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:  passed\n",
      "Example 2:  wrong answer. Expected 'hi there', got 'goodbye\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "program_code = \"print('hello, world!')\"\n",
    "input_data = \"\"\n",
    "expected_output = \"hello, world!\"\n",
    "timeout = 2\n",
    "\n",
    "test_result = check_correctness(program_code, input_data, expected_output, timeout)\n",
    "print(\"Example 1: \", test_result)\n",
    "test_result = check_correctness(\"print('goodbye')\", input_data, \"hi there\", timeout)\n",
    "print(\"Example 2: \", test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5da52f-f804-47b9-989a-25a1b2f461f6",
   "metadata": {},
   "source": [
    "## Part 1: Zero-Shot with Reflection\n",
    "\n",
    "In our first section, we will build a simple zero-shot tool-calling agent to try to solve these problems. We will incorporate a simple form of [reflection](https://www.youtube.com/watch?v=v5ymBTXNqtk) directly in the agent's tool calling schema by adding a \"reasoning\" field. Furthermore, Claude was trained to \"reason\" with freeform text prior to invoking any tools. Together, this should induce reflective \"chain-of-thought\" prompting.\n",
    "\n",
    "_Note: this diverges somewhat from the paper's implementation, which uses an explicit reflection step with a variation of the [Reflexion](../reflexion/reflexion.ipynb) prompt._\n",
    "\n",
    "By the end of this section, we will have built a reflective zero-shot programming agent that looks like the section marked \"Part 1\" in the system diagram below:\n",
    "\n",
    "![Part 1 diagram](./img/diagram-part-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f91dac-d13b-4221-be1b-9254ca849c8d",
   "metadata": {},
   "source": [
    "### State\n",
    "\n",
    "LangGraph's main primitive is the `StateGraph`, which you use to define an agent as a controllable state machine.  The graph has `node`'s (python functions) that perform the work, and `edge`s that define how to route between the nodes.\n",
    "The `State` defines the interface between each node and carries all the information your agent needs.\n",
    "\n",
    "Below, define a `State` for our programming olympiad agent. The `messages` will track the sequence of submissions (and test case feedback) as chat history. The `status` field will flip from `in_progress` to `success` if the submission passes all test cases.\n",
    "The other fields (test_cases, runtime_limit) are used by the `evaluation` node to test the agent's submissions. These values are not seen by the agent itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f43d68d9-10be-4544-879a-88a33db18bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Optional\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class TestCase(TypedDict):\n",
    "    inputs: str\n",
    "    outputs: str\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Append-only chat memory so the agent can try to recover from initial mistakes.\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    # From the dataset. These are used for testing.\n",
    "    test_cases: list[TestCase]\n",
    "    runtime_limit: int\n",
    "    status: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64921a60-411a-4a9b-aaf0-8476d02d8a3a",
   "metadata": {},
   "source": [
    "Now, convert the dataset into inputs our graph will accept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d56776f-993b-4ca7-89ef-21dec01dc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_states = [\n",
    "    {\n",
    "        \"messages\": [(\"user\", row[\"description\"])],\n",
    "        \"test_cases\": row[\"test_cases\"],\n",
    "        \"runtime_limit\": row[\"runtime_limit\"],\n",
    "        \"status\": \"in_progress\",\n",
    "        \"problem_level\": row[\"problem_level\"],\n",
    "    }\n",
    "    for row in ds\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7883ee-b6b3-4d89-b5a5-2e139fe361c9",
   "metadata": {},
   "source": [
    "#### Node 1: Solver\n",
    "\n",
    "Create a `solver` node that prompts an LLM \"agent\" to use a [writePython tool](https://python.langchain.com/docs/integrations/chat/anthropic/#beta-tool-calling) to generate the submitted code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9e7742-16a3-4ad2-bc63-5f9cd4fd734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class writePython(BaseModel):\n",
    "    \"\"\"Write python code that resolves the problem.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(..., description=\"Conceptual solution.\")\n",
    "    pseudocode: str = Field(..., description=\"Detailed English pseudocode.\")\n",
    "    code: str = Field(..., description=\"Valid Python 3 solution to the problem\")\n",
    "\n",
    "\n",
    "class Solver:\n",
    "    def __init__(self, llm: BaseChatModel, prompt: ChatPromptTemplate):\n",
    "        self.runnable = prompt | llm.bind_tools([writePython])\n",
    "\n",
    "    def __call__(self, state: State) -> dict:\n",
    "        # Our agent only can see the \"messages\" and will ignore the test info\n",
    "        return {\"messages\": [self.runnable.invoke({\"messages\": state[\"messages\"]})]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22eaa6d-36ae-4526-9b80-49d615fc055c",
   "metadata": {},
   "source": [
    "Now, create the solver below. We'll use Claude Opus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc472f1-b9b3-4f81-a797-c64704bb07d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************Prompt***********************************\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a world-class competitive programmer.\n",
      "Please reply with a Python 3 solution to the problem below. \n",
      "First, reason through the problem and conceptualize a solution.\n",
      "Then write detailed pseudocode to uncover any potential logical errors or omissions.\n",
      "Finally output the working Python code for your solution, ensuring to fix any errors uncovered while writing pseudocode.\n",
      "\n",
      "No outside libraries are allowed.\u001b[33;1m\u001b[1;3m{examples}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{messages}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# For this section, we are testing zero-shot performance and won't have\n",
    "# any examples. Partial them out to pre-fill the template.\n",
    "prompt = hub.pull(\"wfh/usaco-draft-solver\").partial(examples=\"\")\n",
    "print(\"*\" * 35 + \"Prompt\" + \"*\" * 35)\n",
    "prompt.pretty_print()\n",
    "\n",
    "# Use Haiku if you want to save $$ while (almost) never correctly answering the question\n",
    "# llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "\n",
    "solver = Solver(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9560ba-900a-43d1-ad38-f132fd660337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************Example***********************************\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"<thinking>\\nThe given problem requires designing an algorithm to select a random sample from an infinite stream of data. The key aspects are:\\n\\n- The stream is infinite, so we can't store all elements \\n- We need to select a perfectly random sample, meaning each element has equal probability of being chosen\\n- The sample size is not specified, but let's assume it's a fixed size k\\n\\nThe relevant function to solve this is writePython, which takes the following required parameters:\\n- reasoning: Conceptual solution to the problem \\n- pseudocode: Detailed pseudocode \\n- code: Python code implementing the solution\\n\\nWe have enough information to provide values for each of these parameters based on the problem description. A conceptual solution and pseudocode can be developed, and Python code can implement that solution for a fixed sample size k.\\n</thinking>\", 'type': 'text'}, {'id': 'toolu_01AtVmBMkoo5egFvCcqBPVKm', 'input': {'reasoning': 'To select a random sample of fixed size k from an infinite stream:\\n\\n1. Create a reservoir array of size k to store the sample \\n2. Fill the reservoir array with the first k elements from the stream\\n3. For each subsequent i-th element (i >= k) from the stream:\\n    - Generate a random integer j between 0 and i inclusive\\n    - If j is less than k, replace the element at reservoir[j] with the i-th element\\n4. After the stream ends, the reservoir array contains the random sample\\n\\nThis works because at the i-th element, the probability it is selected is k/i. At the same time, the probability a previously selected element is replaced is 1/i. Combined, this gives each element an equal k/i * 1/i = k/i^2 probability of being in the final sample.', 'pseudocode': '- Initialize:\\n    - reservoir <- new array of size k\\n    - i <- 0\\n- For each element from stream: \\n    - If i < k:\\n        - reservoir[i] <- element\\n    - Else:\\n        - j <- random integer between 0 and i inclusive\\n        - If j < k:\\n            - reservoir[j] <- element\\n    - i <- i + 1\\n- Return reservoir', 'code': 'import random\\n\\ndef selectRandomSample(stream, k):\\n    reservoir = [0] * k\\n    i = 0\\n    \\n    for element in stream:\\n        if i < k:\\n            reservoir[i] = element\\n        else:\\n            j = random.randint(0, i)\\n            if j < k:\\n                reservoir[j] = element\\n        i += 1\\n        \\n    return reservoir'}, 'name': 'writePython', 'type': 'tool_use'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 34 + \" Example \" + \"*\" * 34)\n",
    "result = solver(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"How do I get a perfectly random sample from an infinite stream\",\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "result[\"messages\"][0].pretty_print()\n",
    "# Could expand to include (1)\n",
    "# 1. Restate the problem in plain English\n",
    "# 2. Closely following the explanation, restate and explain the solution in plain English\n",
    "# 3. Write a pseudocode solution\n",
    "# 4. Output the final Python solution with your solution steps in comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c5fa7a-a2eb-4954-be34-4194a58f00d3",
   "metadata": {},
   "source": [
    "#### Node 2: Evaluate\n",
    "\n",
    "Now define the \"`evaluate`\" node. This node takes the `solver`'s submitted code and executes it against the `test_cases` in our `State`.\n",
    "This uses the unsafe `check_correctness` utility we defined in the setup above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1785015b-24f8-415f-b950-e229b5137887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "# This is the node we will add to the graph.\n",
    "# Most tool-calling APIs require that the `ToolMessage` contain the ID\n",
    "# of the\n",
    "def format_tool_message(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response + \"\\nMake all fixes using the writePython tool.\",\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate(state: State):\n",
    "    test_cases = state[\"test_cases\"]\n",
    "    runtime_limit = state[\"runtime_limit\"]\n",
    "    ai_message: AIMessage = state[\"messages\"][-1]\n",
    "    if not ai_message.tool_calls:\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=\"No code submitted. Please try again using the correct python code.\"\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    try:\n",
    "        code = ai_message.tool_calls[0][\"args\"][\"code\"]\n",
    "    except Exception as e:\n",
    "        return {\"messages\": [format_tool_message(repr(e), ai_message)]}\n",
    "    num_test_cases = len(test_cases)\n",
    "    succeeded = 0\n",
    "    test_results = []\n",
    "    # TODO: Multiprocess\n",
    "    for test_case in test_cases:\n",
    "        input_data = test_case[\"inputs\"]\n",
    "        expected_output = test_case[\"outputs\"]\n",
    "        test_result = check_correctness(code, input_data, expected_output, timeout)\n",
    "        test_results.append(test_result)\n",
    "        if test_result == \"passed\":\n",
    "            succeeded += 1\n",
    "    pass_rate = succeeded / num_test_cases if num_test_cases else \"N/A\"\n",
    "    if pass_rate == 1:\n",
    "        return {\"status\": \"success\"}\n",
    "\n",
    "    responses = \"\\n\".join(\n",
    "        [f\"<test id={i}>\\n{r}\\n</test>\" for i, r in enumerate(test_results)]\n",
    "    )\n",
    "    response = f\"Incorrect submission. Please respond with updated code.\\nPass rate: {succeeded}/{num_test_cases}\\nResults:\\n{responses}\"\n",
    "    formatted_message = format_tool_message(response, ai_message)\n",
    "    return {\"messages\": [formatted_message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f2a46d-c3e2-49d4-b44b-cadb6fd4e5a0",
   "metadata": {},
   "source": [
    "#### Create Graph\n",
    "\n",
    "Now, put it all together! Once you've defined each node, defining the connectivity / state transitions is fairly easy.\n",
    "\n",
    "Our Zero-shot graph defines a loop. If we visualize the data flow, we want the logic to:\n",
    "1. First go to the `solver`, which attempts a first solution.\n",
    "2. Next go to the `evaluate` node, which tests the solution.\n",
    "3. If the solution passes, end, otherwise, return to the `solver` to try again.\n",
    "\n",
    "In LangGraph, we use `conditional_edges` to define state transitions that contain conditional logic.\n",
    "Below, define the graph, adding a `control_edge` to handle step (3) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf1560e-1517-4229-8a43-186816da6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"solver\", solver)\n",
    "builder.set_entry_point(\"solver\")\n",
    "builder.add_node(\"evaluate\", evaluate)\n",
    "builder.add_edge(\"solver\", \"evaluate\")\n",
    "\n",
    "\n",
    "def control_edge(state: State):\n",
    "    if state.get(\"status\") == \"success\":\n",
    "        return END\n",
    "    return \"solver\"\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\"evaluate\", control_edge, {END: END, \"solver\": \"solver\"})\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7275a2c3-1818-4d14-a7a5-97bc56243a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b1bb4-262f-41c3-822d-e015daf0744a",
   "metadata": {},
   "source": [
    "Now that we've created our graph, let's see the type of question it will have to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "308d6e18-69ad-4e8d-9c5f-06111b0806ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Farmer John has $N$ ($1 \\leq N \\leq 2 \\cdot 10^5$) farms, numbered from $1$ to\n",
      "$N$. It is known that FJ closes farm $i$ at time $c_i$. Bessie wakes up at time\n",
      "$S$, and wants to maximize the productivity of her day by visiting as many farms\n",
      "as possible before they close. She plans to visit farm $i$ on time $t_i + S$.\n",
      "Bessie must arrive at a farm strictly before Farmer John closes it to actually visit it.\n",
      "\n",
      "Bessie has $Q$ $(1 \\leq Q \\leq 2 \\cdot 10^5)$ queries. For each query, she gives\n",
      "you two integers $S$ and $V$. For each query, output whether Bessie can visit at\n",
      "least $V$ farms if she wakes up at time $S$.\n",
      "\n",
      "INPUT FORMAT (input arrives from the terminal / stdin):\n",
      "The first line consists of $N$ and $Q$.\n",
      "\n",
      "The second line consists of $c_1, c_2, c_3 \\dots c_N$ ($1 \\leq c_i \\leq 10^6$).\n",
      "\n",
      "The third line consists of $t_1, t_2, t_3 \\dots t_N$ ($1 \\leq t_i \\leq 10^6$).\n",
      "\n",
      "The next $Q$ lines each consist of two integers $V$ ($1 \\leq V \\leq N$) and $S$\n",
      "($1 \\leq S \\leq 10^6$).\n",
      "\n",
      "OUTPUT FORMAT (print output to the terminal / stdout):\n",
      "For each of the $Q$ queries, output YES or NO on a new line.\n",
      "\n",
      "SAMPLE INPUT:\n",
      "5 5\n",
      "3 5 7 9 12\n",
      "4 2 3 3 8\n",
      "1 5\n",
      "1 6\n",
      "3 3\n",
      "4 2\n",
      "5 1\n",
      "SAMPLE OUTPUT: \n",
      "YES\n",
      "NO\n",
      "YES\n",
      "YES\n",
      "NO\n",
      "\n",
      "For the first query, Bessie will visit the farms at time $t = [9, 7, 8, 8, 13]$,\n",
      "so she will only get to visit farm $4$ on time before FJ closes the farm.\n",
      "\n",
      "For the second query, Bessie will not be able to visit any of the farms on time.\n",
      "\n",
      "For the third query, Bessie will visit farms $3, 4, 5$ on time.\n",
      "\n",
      "For the fourth and fifth queries, Bessie will be able to visit all but the first\n",
      "farm on time.\n",
      "\n",
      "SCORING:\n",
      "Inputs 2-4: $N,Q\\le 10^3$Inputs 5-9: $c_i, t_i \\le 20$Inputs 10-17: No additional constraints.\n",
      "\n",
      "\n",
      "Problem credits: Chongtian Ma\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_state = input_states[0].copy()\n",
    "# We will reduce the test cases to speed this notebook up\n",
    "input_state[\"test_cases\"] = input_state[\"test_cases\"][:3]\n",
    "print(input_state[\"messages\"][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c444be0-4c7d-49cc-9aaa-2b99dabe3922",
   "metadata": {},
   "source": [
    "Pretty difficult! Let's run our simple \"zero-shot\" agent below to see how it fares. **It most likely will not be able to solve this question** (unless you are using a more powerful model than what I had available at the time of writing this tutorial (2024/04/20).\n",
    "We will trace the trajectory to LangSmith to review the series of submissions. To reduce the packet size, we will use \"`hide_inputs`\" and filter out the test_cases. All this is optional but useful for development. \n",
    "\n",
    "**Note:** We _expect_ a **GraphRecursionError** here from it not being able to answer it correctly in the allocated number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ebe0da0-8f27-4805-829c-54bc1dc29ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': \"<thinking>\\nThe key pieces of informati\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'id': 'toolu_013zRr1Kwb86hHFwkZ9CvpZn', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'id': 'toolu_015bqA7g5BdgiNMD2zjSzkPm', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'id': 'toolu_0197dULeXoTkPaaVkEjjKe61', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: <result>\\nI apologize, but after carefully reviewi\n",
      "Assistant: No code submitted. Please try again using the corr\n",
      "Assistant: [{'text': \"<thinking>\\nYou're absolutely right, I \n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'id': 'toolu_01ScGxFZAmzuDE6tozSc85br', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'id': 'toolu_01G61PAeSK6FiiCZVthhPXZ7', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: <result>\\nI apologize, but after carefully reviewi\n",
      "Assistant: No code submitted. Please try again using the corr\n",
      "Assistant: [{'text': \"<thinking>\\nYou're right, I apologize f\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'id': 'toolu_0171DDkfMLUf4knqt4EkwBms', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'id': 'toolu_01YLmKKqQaAndDdqGfAQ9Xe1', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracing_v2_enabled(client\u001b[38;5;241m=\u001b[39mclient):\n\u001b[1;32m     16\u001b[0m     events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(input_state)\n\u001b[0;32m---> 17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBaseMessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/code/lc/langgraph/langgraph/pregel/__init__.py:645\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before_nodes, interrupt_after_nodes, debug)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m step \u001b[38;5;241m==\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    649\u001b[0m     )\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# before execution, check if we should interrupt\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_interrupt(\n\u001b[1;32m    653\u001b[0m     checkpoint,\n\u001b[1;32m    654\u001b[0m     interrupt_before_nodes,\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_list,\n\u001b[1;32m    656\u001b[0m     next_tasks,\n\u001b[1;32m    657\u001b[0m ):\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError(\"Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Read timed out. (read timeout=10.0)\\n\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from langsmith import Client\n",
    "\n",
    "\n",
    "# We don't need to include all the test cases in our traces.\n",
    "def _hide_test_cases(inputs):\n",
    "    copied = inputs.copy()\n",
    "    # These are tens of MB in size. No need to send them up\n",
    "    copied[\"test_cases\"] = f\"...\"\n",
    "    return copied\n",
    "\n",
    "\n",
    "client = Client(hide_inputs=_hide_test_cases, hide_outputs=_hide_test_cases)\n",
    "with tracing_v2_enabled(client=client):\n",
    "    events = graph.stream(input_state)\n",
    "    for event in events:\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\n",
    "                    \"Assistant:\",\n",
    "                    str(value[\"messages\"][-1].content).replace(\"\\n\", \"\\\\n\")[:50],\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c496d9a-a95b-4cab-86fa-daafc7ddd065",
   "metadata": {},
   "source": [
    "It wasn't able to solve it in time **but that's OK**! If it were easy, this paper would be a lot shorter :)\n",
    "\n",
    "You can vew the [agent's full LangSmith trace](https://smith.langchain.com/public/61c84ad0-51db-40f1-b50d-6983d9481ca1/r) at the provided link.\n",
    "\n",
    "In the next section we will add an improvement: \"episodic memory\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090a1639-09c5-4682-813f-71100f236eb3",
   "metadata": {},
   "source": [
    "## Part 2: Few-shot Retrieval\n",
    "\n",
    "Even with reflective tool calling, our baseline agent from part 1 struggled with this difficult task. One way to \"teach\" an LLM how to better perform a task is through demonstrations, also known as \"few-shot examples.\"\n",
    "\n",
    "What the authors of the USACO paper call \"episodic memory\" **is really just few-shot prompting over similar examples.**\n",
    "\n",
    "Each examples in this case is a different problems + solution within the dataset. The term \"episodic memory\" makes sense if you pretend your agent has already \"solved\" these problems and is recalling its solutions to them.\n",
    "\n",
    "This section adds the \"Episodic Memory\" components from \"Part 2\" in the diagram below.\n",
    "\n",
    "![Part 2 diagram](./img/diagram-part-2.png)\n",
    "\n",
    "Note that this memory step is performed **one time**,  **before** the logic of our zero-shot loop from part 1. The steps are as follows:\n",
    "\n",
    "1. Prompt the LLM to generate a candidate solution.\n",
    "2. Use the text of the candidate solution to retrieve the N most similar (problem, solution) pairs.\n",
    "3. Format this result in the Zero-shot agent's prompt.\n",
    "\n",
    "Below, let's implement our episodic memory as a retriever. We will follow the paper's retriever selection and use [BM25](https://en.wikipedia.org/wiki/Okapi_BM25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612dd8d-31af-426c-944b-203acd55ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e0c485-8eba-41e6-ae29-64bcea98d19e",
   "metadata": {},
   "source": [
    "#### State\n",
    "\n",
    "The state is mostly recycled from part 1. Add additional \"candidate\" and \"examples\" fields to store the information for the memory steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "16937fef-58b9-4ab2-bbfc-5237aad235ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Optional\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class TestCase(TypedDict):\n",
    "    inputs: str\n",
    "    outputs: str\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # NEW! Candidate for retrieval + formatted fetched examples as \"memory\"\n",
    "    candidate: AIMessage\n",
    "    examples: str\n",
    "    # Repeated from Part 1\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    test_cases: list[TestCase]\n",
    "    runtime_limit: int\n",
    "    status: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb9104-e73f-47db-9af5-84a375a8d323",
   "metadata": {},
   "source": [
    "#### Nodes 1 and 3: Draft & Solver\n",
    "\n",
    "Let's create our \"agent\". We will modify the `Solver` from Part 1 to reuse it for  for the agent node and for the candidate program generation node (\"draft\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "25f947a7-15bb-4119-a47e-b5c33ca0a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "\n",
    "class Solver:\n",
    "    def __init__(self, llm: BaseChatModel, prompt: ChatPromptTemplate):\n",
    "        self.runnable = prompt | llm.bind_tools([writePython])\n",
    "\n",
    "    def __call__(self, state: State) -> dict:\n",
    "        # Our agent only can see the \"messages\" and will ignore the test info\n",
    "        inputs = {\"messages\": state[\"messages\"]}\n",
    "        has_examples = bool(state.get(\"examples\"))\n",
    "        output_key = \"candidate\"  # Used in the draft node\n",
    "        if has_examples:\n",
    "            output_key = \"messages\"\n",
    "            # Used in the solve node\n",
    "            inputs[\"examples\"] = state[\"examples\"]\n",
    "        response = self.runnable.invoke(inputs)\n",
    "        if not response.content:\n",
    "            return {\n",
    "                output_key: AIMessage(\n",
    "                    content=\"I'll need to think about this step by step.\"\n",
    "                )\n",
    "            }\n",
    "        return {output_key: response}\n",
    "\n",
    "\n",
    "prompt = hub.pull(\"wfh/usaco-draft-solver\")\n",
    "llm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "\n",
    "draft_solver = Solver(llm, prompt.partial(examples=\"\"))\n",
    "solver = Solver(llm, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a526b-3b52-4630-a58e-0317a0034609",
   "metadata": {},
   "source": [
    "#### Node 2: Retrieve\n",
    "\n",
    "The retrieve node takes a candidate solution (made by the 'solver' node), uses _this_ to search for similar examples, then formats those in the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e5e0aa40-79a4-4071-9ad2-9aa2f36599ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will test our agent on index 0 (the same as above).\n",
    "# Later, we will test on index 2 (the first 'silver difficulty' question)\n",
    "test_indices = [0, 2]\n",
    "train_ds = [row for i, row in enumerate(ds) if i not in test_indices]\n",
    "test_ds = [row for i, row in enumerate(ds) if i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "96a1ff96-7556-4959-9f54-1ade3bd1c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "\n",
    "def format_example(row):\n",
    "    question = row[\"description\"]\n",
    "    answer = row[\"solution\"]\n",
    "    return f\"\"\"<problem>\n",
    "{question}\n",
    "</problem>\n",
    "<solution>\n",
    "{answer}\n",
    "</solution>\"\"\"\n",
    "\n",
    "\n",
    "# Skip our 'test examples' to avoid cheating\n",
    "# This is \"simulating\" having seen other in-context examples\n",
    "retriever = BM25Retriever.from_texts([format_example(row) for row in train_ds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad20d3a-291c-41a5-a343-bd14284f76f2",
   "metadata": {},
   "source": [
    "Now define the node. Any node can optionally accept a second `config` positional argument. This contains `configurable` params you can adjust when invoking the graph. For instance, we can\n",
    "adjust the top `k` examples to retrieve for our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "af42962d-c06e-4b6e-96df-72ad48f17617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "def retrieve_examples(state: State, config: RunnableConfig):\n",
    "    top_k = config[\"configurable\"].get(\"k\") or 2\n",
    "    ai_message: AIMessage = state[\"candidate\"]\n",
    "    if not ai_message.tool_calls:\n",
    "        # We err here. To make more robust, you could loop back\n",
    "        raise ValueError(\"Draft agent did not produce a valid code block\")\n",
    "    code = ai_message.tool_calls[0][\"args\"][\"code\"]\n",
    "    examples_str = \"\\n\".join(\n",
    "        [doc.page_content for doc in retriever.invoke(code)[:top_k]]\n",
    "    )\n",
    "    examples_str = f\"\"\"\n",
    "You previously solved the following problems in this competition:\n",
    "<Examples>\n",
    "{examples_str}\n",
    "<Examples>\n",
    "Approach this new question with similar sophistication.\"\"\"\n",
    "    return {\"examples\": examples_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5cbe72-fca0-4974-a769-284267d3df91",
   "metadata": {},
   "source": [
    "#### Graph\n",
    "\n",
    "Now let's put it all together. The graph is slightly more complicated than in part 1, since we have to add the initial \"draft\" and \"retrieve\" nodes to our agent loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e6e73e85-1232-4848-beba-3139ac7d0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"draft\", draft_solver)\n",
    "builder.set_entry_point(\"draft\")\n",
    "builder.add_node(\"retrieve\", retrieve_examples)\n",
    "builder.add_node(\"solve\", solver)\n",
    "builder.add_node(\"evaluate\", evaluate)\n",
    "# Add connectivity\n",
    "builder.add_edge(\"draft\", \"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"solve\")\n",
    "builder.add_edge(\"solve\", \"evaluate\")\n",
    "\n",
    "\n",
    "def control_edge(state: State):\n",
    "    if state.get(\"status\") == \"success\":\n",
    "        return END\n",
    "    return \"solve\"\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\"evaluate\", control_edge, {END: END, \"solve\": \"solve\"})\n",
    "\n",
    "\n",
    "checkpointer = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57acf78d-5e68-46dd-adae-2259e5c5d3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb633e0-0d02-4050-96a8-18265594385b",
   "metadata": {},
   "source": [
    "Let's try again on this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc6f0455-a6e9-46a0-8f8b-03de00fb1f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"<thinking>\\nThe key aspects of this problem are:\\n1. We have N farms, each with a closing time c_i and a travel time t_i from Bessie's starting point. \\n2. Bessie wakes up at time S for eac\n",
      "Retrieved examples:\n",
      "\n",
      " \n",
      "You previously solved the following problems in this competition:\n",
      "<Examples>\n",
      "<problem>\n",
      "Bessie is bo...\n",
      "Assistant: [{'text': \"<thinking>\\nThe relevant tool here is w\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"question-1\", \"k\": 2}}\n",
    "with tracing_v2_enabled(client=client):\n",
    "    events = graph.stream(input_state, config)\n",
    "    for event in events:\n",
    "        for value in event.values():\n",
    "            messages = value.get(\"messages\")\n",
    "            if messages:\n",
    "                print(\n",
    "                    \"Assistant:\",\n",
    "                    str(value[\"messages\"][-1].content).replace(\"\\n\", \"\\\\n\")[:50],\n",
    "                )\n",
    "            elif value.get(\"examples\"):\n",
    "                print(\"Retrieved examples:\\n\\n\", value[\"examples\"][:100] + \"...\")\n",
    "            elif value.get(\"candidate\"):\n",
    "                print(str(value[\"candidate\"].content)[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389ffb0-839e-4646-be68-dbc79279c8ae",
   "metadata": {},
   "source": [
    "**No recursion error!** You can view the [full LangSmith trace](https://smith.langchain.com/public/1f1c4db3-b53c-49bf-a287-a2b51c081156/r/31f90ddd-8ae9-4b23-a2b5-b0c0d67c5cc3) of the graph's execution at the provided link to confirm the results. You can also check the graph state to confirm that it passed all test cases successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d55a1d95-9fa4-45b2-9f5e-7ca02fb8415b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = graph.get_state(config)\n",
    "checkpoint.values[\"status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50348c66-4d38-44d0-bb20-ae1a14517f78",
   "metadata": {},
   "source": [
    "**Congrats!** You added \"episodic memory\" to your agent to fetch few-shot examples and solve this bronze level programming olympiad question!\n",
    "\n",
    "Our agent is still limited, however. Let's test it out on a more challenging silver level question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ef0b06f-c448-49a5-8f1f-f7041a5d6b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'silver'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver_row = test_ds[1]\n",
    "silver_row[\"problem_level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "2ae55ddc-e629-4be7-badd-756608eec50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"<thinking>\\nTo solve this problem, we need to:\\n1. Read in the port connections and directions\\n2. Simulate Bessie's journey by following the directions K times\\n3. Output the final port Be\n",
      "Retrieved examples:\n",
      "\n",
      " \n",
      "You previously solved the following problems in this competition:\n",
      "<Examples>\n",
      "<problem>\n",
      "\n",
      "Farmer John...\n",
      "Assistant: [{'text': '<thinking>\\nTo solve this problem, we n\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'text': \"<thinking>\\nThe previous code submissio\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'text': \"<thinking>\\nThe previous code passed on\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'text': \"<thinking>\\nApologies for the incomplet\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'text': \"<thinking>\\nI apologize for the confusi\n",
      "Assistant: KeyError('code')\\nMake all fixes using the writePy\n",
      "Assistant: [{'id': 'toolu_011YPfiRvvaKv9neSAK9u5B7', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'text': \"<thinking>\\nI apologize for the confusi\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'id': 'toolu_01W5r2VvYVqzN748kZvpY6ru', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'text': \"<thinking>\\nI apologize for the confusi\n",
      "Assistant: KeyError('code')\\nMake all fixes using the writePy\n",
      "Assistant: [{'id': 'toolu_018K78GzDU1t62APrdKyfVUe', 'input':\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Assistant: [{'text': \"<thinking>\\nI apologize for the continu\n",
      "Assistant: KeyError('code')\\nMake all fixes using the writePy\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[312], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracing_v2_enabled(client\u001b[38;5;241m=\u001b[39mclient):\n\u001b[1;32m     11\u001b[0m     events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(silver_input, config)\n\u001b[0;32m---> 12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/lc/langgraph/langgraph/pregel/__init__.py:645\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before_nodes, interrupt_after_nodes, debug)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m step \u001b[38;5;241m==\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    649\u001b[0m     )\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# before execution, check if we should interrupt\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_interrupt(\n\u001b[1;32m    653\u001b[0m     checkpoint,\n\u001b[1;32m    654\u001b[0m     interrupt_before_nodes,\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_list,\n\u001b[1;32m    656\u001b[0m     next_tasks,\n\u001b[1;32m    657\u001b[0m ):\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "silver_input = {\n",
    "    \"messages\": [(\"user\", silver_row[\"description\"])],\n",
    "    \"test_cases\": silver_row[\"test_cases\"],\n",
    "    \"runtime_limit\": silver_row[\"runtime_limit\"],\n",
    "    \"status\": \"in_progress\",\n",
    "}\n",
    "\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"silver-question-1\", \"k\": 2}}\n",
    "with tracing_v2_enabled(client=client):\n",
    "    events = graph.stream(silver_input, config)\n",
    "    for event in events:\n",
    "        for value in event.values():\n",
    "            messages = value.get(\"messages\")\n",
    "            if messages:\n",
    "                if isinstance(messages, list):\n",
    "                    messages = value[\"messages\"][-1]\n",
    "                print(\n",
    "                    \"Assistant:\",\n",
    "                    str(messages.content).replace(\"\\n\", \"\\\\n\")[:50],\n",
    "                )\n",
    "            elif value.get(\"examples\"):\n",
    "                print(\"Retrieved examples:\\n\\n\", value[\"examples\"][:100] + \"...\")\n",
    "            elif value.get(\"candidate\"):\n",
    "                print(str(value[\"candidate\"].content)[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c9217-38de-4f48-9070-2092fd9ecc15",
   "metadata": {},
   "source": [
    "**Still too hard!** AGI not achieved yet. To investigate our agent's trajectory in detail, check out the [full LangSmith trace](https://smith.langchain.com/public/13018b44-0c4f-4f1a-9e6d-dea1f3fd4705/r).\n",
    "\n",
    "Our agent isn't good enough to be autonomous. The great thing about LangGraph is you don't have to decide between \"autonomous agent\" and \"simple DAG\": you can inject control and user-interfaces wherever it can usefully benefit your application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59177162-3fb8-4307-8e7f-ea67e785d4cf",
   "metadata": {},
   "source": [
    "## Part 3: Human-in-the-loop\n",
    "\n",
    "Our retrieval-enhanced agent was able to solve the `bronze`-level question but still failed for those with the more challenging **silver** difficulty. \n",
    "\n",
    "Recall that the paper presented 3 complementary techniques that improved performance:\n",
    "\n",
    "1. Reflection: explicitly prompting the LLM to \"reflect\" on its mistakes can help it\n",
    "2. Few-shot prompting: retrieving relevant, high-quality examples as \"memory\"\n",
    "3. **Human-in-the-loop collaboration:**  without giving the correct answer, the human is allowed to help the agent reflect on its appraoch and point it in a better direction.\n",
    "\n",
    "\n",
    "In this section, we will add the \"human\" node (marked as \"part 3\" in the diagram below), completing our agent graph:\n",
    "\n",
    "![Diagram](./img/diagram.png)\n",
    "\n",
    "From an ML perspective, this is a bit of a [clever hans](https://en.wikipedia.org/wiki/Clever_Hans), but from the application designer's perspective, where the primary goal is to achieve a higher combined success rate, letting the human interject with thoughts and insights is only natural. \n",
    "\n",
    "In either case, adding a human check to a LangGraph instance requires only 1 or 2 extra lines of code. Let's do so by making two changes:\n",
    "\n",
    "1. Add a new \"`human`\" node after the \"`evaluate`\" node to optionally comment on the test results before passing it back to the agent.\n",
    "2. Instruct the graph to `interrupt_before` the \"`human`\" node to give the user a chance to modify the trajectory.\n",
    "\n",
    "\n",
    "Start assembling your graph below. The following section is identical to our application in part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3c6456ba-363c-4133-8631-6dabb042b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all the same as before\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "prompt = hub.pull(\"wfh/usaco-draft-solver\")\n",
    "llm = ChatAnthropic(model=\"claude-3-opus-20240229\", max_tokens_to_sample=4000)\n",
    "\n",
    "draft_solver = Solver(llm, prompt.partial(examples=\"\"))\n",
    "builder.add_node(\"draft\", draft_solver)\n",
    "builder.set_entry_point(\"draft\")\n",
    "builder.add_node(\"retrieve\", retrieve_examples)\n",
    "solver = Solver(llm, prompt)\n",
    "builder.add_node(\"solve\", solver)\n",
    "builder.add_node(\"evaluate\", evaluate)\n",
    "builder.add_edge(\"draft\", \"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"solve\")\n",
    "builder.add_edge(\"solve\", \"evaluate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8faba-a3eb-4dd9-ad17-dfc743baf3a4",
   "metadata": {},
   "source": [
    "Now, add the \"`human`\" node. This is a placeholder node whose **sole purpose is to wait** before passing back to the agent. This gives us the option of weighing in and steering the agent's attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "eb81a1f2-04f9-42be-bc71-073bd20b11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_node(\"human\", lambda state: {})\n",
    "# Always give back to the agent\n",
    "builder.add_edge(\"human\", \"solve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d837103-ede4-4515-a0cd-0b3319382013",
   "metadata": {},
   "source": [
    "Now finish by updating the control edge, this time routing to \"human\" (instead of \"solve\") if the tests fail. Compile the graph with `interrupt_before=[\"human\"]` to instruct the agent to wait for human input before continuing execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "461c13ba-01cc-44e1-b837-6a64d03069d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_edge(state: State):\n",
    "    if state.get(\"status\") == \"success\":\n",
    "        return END\n",
    "    # Modified: used to be \"solve\" in Part 2.\n",
    "    return \"human\"\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\"evaluate\", control_edge, {END: END, \"human\": \"human\"})\n",
    "\n",
    "\n",
    "checkpointer = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    # New: this tells the graph to break any time it goes to the \"human\" node\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "040b2100-5b2e-40c9-b6af-a1b680e16ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372462bf-c74e-4c18-bbee-c21c8132b2e5",
   "metadata": {},
   "source": [
    "As you can see in the graph above, the structure is the same as Part 2, except that we've inserted a \"`human`\" breakpoint between the \"`evaluate`\" and \"`solve`\" nodes.\n",
    "\n",
    "Let's try this question again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "5f9ad0d0-cdaf-4ba2-9527-b5b9739e7b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"<thinking>\\nThe relevant tool here is writePython, since the user has requested a Python solution to this programming problem.\\n\\nLooking at the required parameters for writePython:\\n\\nreas\n",
      "Retrieved examples:\n",
      "\n",
      " \n",
      "You previously solved the following problems in this competition:\n",
      "<Examples>\n",
      "<problem>\n",
      "\n",
      "Farmer John...\n",
      "Assistant: [{'text': '<thinking>\\nThis problem is asking us t\n",
      "Assistant: Incorrect submission. Please respond with updated \n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"silver-hl-1\", \"k\": 2}}\n",
    "with tracing_v2_enabled(client=client):\n",
    "    events = graph.stream(silver_input, config)\n",
    "    for event in events:\n",
    "        for value in event.values():\n",
    "            messages = value.get(\"messages\")\n",
    "            if messages:\n",
    "                if isinstance(messages, list):\n",
    "                    messages = value[\"messages\"][-1]\n",
    "                print(\n",
    "                    \"Assistant:\",\n",
    "                    str(messages.content).replace(\"\\n\", \"\\\\n\")[:50],\n",
    "                )\n",
    "            elif value.get(\"examples\"):\n",
    "                print(\"Retrieved examples:\\n\\n\", value[\"examples\"][:100] + \"...\")\n",
    "            elif value.get(\"candidate\"):\n",
    "                print(str(value[\"candidate\"].content)[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947e3089-6ae5-40e4-b993-7ef7e8630a12",
   "metadata": {},
   "source": [
    "**Time to weigh in:** our model failed in its first attempt, so we have the opportunity to give it some advice.\n",
    "\n",
    "Recall the original question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4fcdf8c9-6a5a-4463-90ae-eec89a57cd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 3: Luxury River Cruise [Josh Alman and Nathan Pinsker, 2013]\n",
      "\n",
      "Farmer John is taking Bessie and the cows on a cruise! They are sailing on a \n",
      "network of rivers with N ports (1 <= N <= 1,000) labeled 1..N, and Bessie \n",
      "starts at port 1. Each port has exactly two rivers leading out of it which \n",
      "lead directly to other ports, and rivers can only be sailed one way.\n",
      "\n",
      "At each port, the tour guides choose either the \"left\" river or the \"right\" \n",
      "river to sail down next, but they keep repeating the same choices over and \n",
      "over. More specifically, the tour guides have chosen a short sequence of M \n",
      "directions (1 <= M <= 500), each either \"left\" or \"right\", and have\n",
      "repeated it K times (1 <= K <= 1,000,000,000). Bessie thinks she is going\n",
      "in circles -- help her figure out where she ends up!\n",
      "\n",
      "PROBLEM NAME: cruise\n",
      "\n",
      "INPUT FORMAT:\n",
      "\n",
      "* Line 1: Three space-separated integers N, M, and K.\n",
      "\n",
      "* Lines 2..N+1: Line i+1 has two space-separated integers,\n",
      "        representing the number of the ports that port i's left and\n",
      "        right rivers lead to, respectively.\n",
      "\n",
      "* Line N+2: M space-separated characters, either 'L' or 'R'. 'L'\n",
      "        represents a choice of  'left' and 'R' represents a choice of\n",
      "        'right'.\n",
      "\n",
      "SAMPLE INPUT:\n",
      "\n",
      "4 3 3\n",
      "2 4\n",
      "3 1\n",
      "4 2\n",
      "1 3\n",
      "L L R\n",
      "\n",
      "INPUT DETAILS:\n",
      "\n",
      "The port numbers are arranged clockwise in a circle, with 'L' being a \n",
      "clockwise rotation and 'R' being a counterclockwise rotation. The sequence \n",
      "taken is LLRLLRLLR.\n",
      "\n",
      "OUTPUT FORMAT:\n",
      "\n",
      "* Line 1: A single integer giving the number of the port where\n",
      "        Bessie's cruise ends.\n",
      "\n",
      "SAMPLE OUTPUT:\n",
      "\n",
      "4\n",
      "\n",
      "OUTPUT DETAILS:\n",
      "\n",
      "After the first iteration of the sequence of directions, Bessie is at port\n",
      "2 (1 -> 2 -> 3 -> 2); after the second, she is at port 3 (2 -> 3 -> 4 ->\n",
      "3), and at the end she is at port 4 (3 -> 4 -> 1 -> 4).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "print(snapshot.values[\"messages\"][0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ed165-e2cf-495f-a4bb-a0f3f87a719c",
   "metadata": {},
   "source": [
    "And then review the agent's current submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2049980a-0a0c-4135-98c7-d4de1af4757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking>\n",
      "This problem is asking us to simulate Bessie's journey along the river network, following the repeated sequence of left/right directions. The key aspects are:\n",
      "\n",
      "1. We have a river network represented as a graph, with each port having a \"left\" and \"right\" outgoing edge to other ports. \n",
      "2. There is a sequence of M directions (L or R) that is repeated K times.\n",
      "3. We need to determine Bessie's final port after following this repeated sequence starting from port 1.\n",
      "\n",
      "To solve this, the main steps would be:\n",
      "1. Read in the river network graph \n",
      "2. Read in the sequence of directions\n",
      "3. Simulate Bessie's journey by repeatedly following the direction sequence K times, updating her current port each step\n",
      "4. Output the final port Bessie ends up at\n",
      "\n",
      "The provided tools would allow us to implement this solution in Python. We have the port count N, sequence length M, repetition count K, the graph edges, and direction sequence all provided as inputs. So we have the necessary parameters to invoke writePython with a solution.\n",
      "</thinking>\n",
      "\n",
      "\n",
      "Code:\n",
      "\n",
      "\n",
      "N, M, K = map(int, input().split())\n",
      "graph = [[] for _ in range(N+1)]  # adjacency list, ignore index 0\n",
      "\n",
      "for _ in range(N):\n",
      "    left, right = map(int, input().split())\n",
      "    graph[i].append(left)\n",
      "    graph[i].append(right)\n",
      "\n",
      "directions = input().split()\n",
      "\n",
      "cur = 1  # start at port 1\n",
      "for _ in range(K):\n",
      "    for d in directions:\n",
      "        if d == 'L':\n",
      "            cur = graph[cur][0]\n",
      "        else:  # d == 'R'\n",
      "            cur = graph[cur][1]\n",
      "            \n",
      "print(cur)\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "print(snapshot.values[\"messages\"][-2].content[0][\"text\"])\n",
    "print(\"\\n\\nCode:\\n\\n\")\n",
    "print(snapshot.values[\"messages\"][-2].tool_calls[0][\"args\"][\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "69fd7efa-acbc-4450-927e-fb2b760066b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect submission. Please respond with updated code.\n",
      "Pass rate: 0/10\n",
      "Results:\n",
      "<test id=0>\n",
      "failed: Traceback (most recent call last):\n",
      "  File \"<string>\", line 6, in <module>\n",
      "NameError: name 'i' is no\n"
     ]
    }
   ],
   "source": [
    "print(snapshot.values[\"messages\"][-1].content[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb3b34-8c67-4ceb-95ff-4ac65053c8a4",
   "metadata": {},
   "source": [
    "The agent failed. It's on the right track but clearly doesn't handle all the edge cases.\n",
    "\n",
    "The agent needs to remember that simulation should include the cycle + whatever steps led up to the example. It could use the \"tortoise and hare\" algo for cycle detection, use the simulated path and break if and when a repeat is detected, and then \n",
    "\n",
    "Let's let the agent know this by **updating the graph state**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b10fcbc9-6dd4-41ad-98f7-1cf1685035e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_config = graph.update_state(\n",
    "    config,\n",
    "    values={\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                f\"\"\"Consider breaking down the algorithm into separate parts: reading inputs, detecting cycles using the tortoise and hare algorithm, and determining Bessie's final position by skipping ahead K steps.\n",
    "\n",
    "Read the inputs into three arrays:\n",
    "- Two arrays L and R for the ports (adjust for 0-based indexing)\n",
    "- A third array S for the direction sequence\n",
    "\n",
    "Optimize by multiplying K by M before the main loop to convert the number of repetitions into the total number of steps.\n",
    "\n",
    "Use the tortoise and hare algorithm to detect the cycle:\n",
    "- Define a helper function get_next(v) that returns the next position and direction index\n",
    "- Initialize two pointers s0 and s1 to (0, 0)\n",
    "- In each iteration:\n",
    "  - Move s0 by 1 step and s1 by 2 steps using get_next()\n",
    "  - If s0 equals s1, decrement K by 1 and break out of the loop\n",
    "  - Otherwise, decrement K by 1\n",
    "- After the loop, if K is not 0, there is a cycle\n",
    "\n",
    "To find the cycle length:\n",
    "- Initialize a counter variable rho to 1\n",
    "- Move s0 by 1 step using get_next()\n",
    "- Enter a loop:\n",
    "  - Move s0 by 1 step using get_next()\n",
    "  - Increment rho\n",
    "  - If s0 equals s1, break out of the loop\n",
    "\n",
    "Skip ahead by reducing K modulo rho.\n",
    "\n",
    "Simulate the remaining steps:\n",
    "- While K > 0, move s0 to the next position using get_next() and decrement K\n",
    "\n",
    "Print the final position (converted to 1-based indexing).\n",
    "\n",
    "Pay close attention to the initialization and movement of pointers during cycle detection and length calculation. Ensure that the logic is correct and handles all cases accurately.\"\"\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0542e9b-0992-407e-967f-c43bf1a75cc6",
   "metadata": {},
   "source": [
    "Now the graph's state contains our new message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "818e93f2-2204-4704-a832-f5c102d330f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content=\"Consider breaking down the algorithm into separate parts: reading inputs, detecting cycles using the tortoise and hare algorithm, and determining Bessie's final position by skipping ahead K steps.\\n\\nRead the inputs into three arrays:\\n- Two arrays L and R for the ports (adjust for 0-based indexing)\\n- A third array S for the direction sequence\\n\\nOptimize by multiplying K by M before the main loop to convert the number of repetitions into the total number of steps.\\n\\nUse the tortoise and hare algorithm to detect the cycle:\\n- Define a helper function get_next(v) that returns the next position and direction index\\n- Initialize two pointers s0 and s1 to (0, 0)\\n- In each iteration:\\n  - Move s0 by 1 step and s1 by 2 steps using get_next()\\n  - If s0 equals s1, decrement K by 1 and break out of the loop\\n  - Otherwise, decrement K by 1\\n- After the loop, if K is not 0, there is a cycle\\n\\nTo find the cycle length:\\n- Initialize a counter variable rho to 1\\n- Move s0 by 1 step using get_next()\\n- Enter a loop:\\n  - Move s0 by 1 step using get_next()\\n  - Increment rho\\n  - If s0 equals s1, break out of the loop\\n\\nSkip ahead by reducing K modulo rho.\\n\\nSimulate the remaining steps:\\n- While K > 0, move s0 to the next position using get_next() and decrement K\\n\\nPrint the final position (converted to 1-based indexing).\\n\\nPay close attention to the initialization and movement of pointers during cycle detection and length calculation. Ensure that the logic is correct and handles all cases accurately.\", id='63a97bf2-b342-4f9b-a930-f89d9fd352e2')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb67198-c84f-458b-8baf-783d7246dddc",
   "metadata": {},
   "source": [
    "Let's let the agent try again. Call `stream` with `None` to just use the inputs loaded from the memory. We will skip our human review for the next few attempats\n",
    "to see if it can correct itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d5d76d8f-e49b-46bf-a762-a6c6978ee96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': \"<thinking>\\nThank you for the detailed \n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Continuing...\n"
     ]
    }
   ],
   "source": [
    "num_trials = 1\n",
    "with tracing_v2_enabled(client=client):\n",
    "    for _ in range(num_trials):\n",
    "        events = graph.stream(None, updated_config)\n",
    "        for event in events:\n",
    "            for value in event.values():\n",
    "                messages = value.get(\"messages\")\n",
    "                if messages:\n",
    "                    if isinstance(messages, list):\n",
    "                        messages = value[\"messages\"][-1]\n",
    "                    print(\n",
    "                        \"Assistant:\",\n",
    "                        str(messages.content).replace(\"\\n\", \"\\\\n\")[:50],\n",
    "                    )\n",
    "                elif value.get(\"examples\"):\n",
    "                    print(\"Retrieved examples:\\n\\n\", value[\"examples\"][:100] + \"...\")\n",
    "                elif value.get(\"candidate\"):\n",
    "                    print(str(value[\"candidate\"].content)[:200])\n",
    "        if graph.get_state(config).values[\"status\"] == \"success\":\n",
    "            break\n",
    "        print(\"Continuing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "20ee7535-1bc8-4105-87c4-0e7a89a011ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_state = list(graph.get_state_history(config))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a492fd-03fc-4de5-8ba5-3ccdaeb1791c",
   "metadata": {},
   "source": [
    "OK so the agent tried again. Check out the [LangSmith trace](https://smith.langchain.com/public/707be522-9eaf-4b6a-994e-1742f421a433/r/add3d8e7-85b1-40cf-bbd3-e78c50f835e8) from this step to see its update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1f691881-f56e-4e2c-8b6a-5febb7ccf3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(most_recent_state.config)\n",
    "ai_message = snapshot.values[\"messages\"][-2]\n",
    "if ai_message.content:\n",
    "    print(ai_message.content)\n",
    "print(\"\\n\\nCode:\\n\\n\")\n",
    "print(ai_message.tool_calls[0][\"args\"][\"code\"] if ai_message.tool_calls else \"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b6fdebe7-557e-4751-97f3-15901c95600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect submission. Please respond with updated code.\n",
      "Pass rate: 8/10\n",
      "Results:\n",
      "<test id=0>\n",
      "wrong answer. Expected '4\n",
      "', got '3\n",
      "'\n",
      "</test>\n",
      "<test id=1>\n",
      "passed\n",
      "</test>\n",
      "<test id=2>\n",
      "passed\n",
      "</test>\n",
      "<test i\n"
     ]
    }
   ],
   "source": [
    "print(snapshot.values[\"messages\"][-1].content[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f9068-3c42-408c-a414-5914f923b78f",
   "metadata": {},
   "source": [
    "Still getting most test cases wrong.\n",
    "\n",
    "Let's provide more feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6eb46517-cdd1-4716-8a9e-df72cdd9ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_config = graph.update_state(\n",
    "    updated_config,\n",
    "    values={\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"\"\"That's better, but you're still getting some errors. Let's double check some things:\n",
    "                       \n",
    "1. When calculating the cycle length, make sure the initialization and movement of the pointers is correct. Double-check the logic there and see if you can spot any discrepancies.\n",
    "2. Check the condition for whether there's a cycle after the main loop to ensure it covers all cases, like if  K becomes 0 in the last iteration.\n",
    "\n",
    "Think step by step through youur implementation and update using the writePython tool.\"\"\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd222b55-9bc5-4db0-8d28-58f366826dd4",
   "metadata": {},
   "source": [
    "Now that we've provided this feedback, let's give the agent a few attempts at solving it before we weigh in again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ab89905b-ab75-4820-bde8-20ae01410aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': \"<thinking>\\nAfter re-analyzing the algo\n",
      "Assistant: Incorrect submission. Please respond with updated \n",
      "Continuing...\n",
      "Assistant: [{'text': \"<thinking>\\nThank you for the breakdown\n"
     ]
    }
   ],
   "source": [
    "num_trials = 2\n",
    "with tracing_v2_enabled(client=client):\n",
    "    for _ in range(num_trials):\n",
    "        events = graph.stream(None, updated_config)\n",
    "        for event in events:\n",
    "            for value in event.values():\n",
    "                messages = value.get(\"messages\")\n",
    "                if messages:\n",
    "                    if isinstance(messages, list):\n",
    "                        messages = value[\"messages\"][-1]\n",
    "                    print(\n",
    "                        \"Assistant:\",\n",
    "                        str(messages.content).replace(\"\\n\", \"\\\\n\")[:50],\n",
    "                    )\n",
    "                elif value.get(\"examples\"):\n",
    "                    print(\"Retrieved examples:\\n\\n\", value[\"examples\"][:100] + \"...\")\n",
    "                elif value.get(\"candidate\"):\n",
    "                    print(str(value[\"candidate\"].content)[:200])\n",
    "        if graph.get_state(config).values[\"status\"] == \"success\":\n",
    "            break\n",
    "        print(\"Continuing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28446ca4-0063-4ac2-bd87-bb9319fef84c",
   "metadata": {},
   "source": [
    "You can review [a LangSmith trace (link)](https://smith.langchain.com/public/d383e743-f8f1-4206-9dce-47627f152612/r/3f89582f-9107-461a-a34e-608d52641eeb) of the agent's response to your feedback at the provided link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "28afec75-d661-4b88-b295-edb886231693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "print(snapshot.values[\"status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72327753-b8b6-4cbc-b5cc-b3cd90b7dd2e",
   "metadata": {},
   "source": [
    "**Success!** - the LLM really wouldn't have been able to come to the correct answer without detailed human involvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2d6e8-3daf-4cbe-acb9-387e3058e602",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats on making it to the end! In this tutorial, you implemented an agent in LangGraph capable of solving challenging programming problems. You did so by leveraging a few common techniques to improve performance, including:\n",
    "\n",
    "1. **Reflection**: while we didn't implement an explicit reflection step, our prompt and tool invocation was designed to encourage critique of previous outputs. You added this in Part 1.\n",
    "2. **Retrieval**: the \"episodic memory\" of the agent retrieves high-quality few-shot examples from our corpora of programming problems to help solve the **bronze** level question. In Part 2, you implemented a retrieval memory as an initial step.\n",
    "3. **Human-in-the-loop**: LLM-powered agents are still too weak to answer all these questions autonomously, but at times, they can get most of the way there and land on the right answer with human feedback. In Part 3, you used `interrupt_before` on an additional placeholder \"human\" node and then included your feedback by using `update_state` on the graph.\n",
    "\n",
    "\n",
    "LLMs are not capable of solving all these problems autonomously, but through better prompting and clever engineering, you can create a system that is able to more reliably arrive at the proper solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
